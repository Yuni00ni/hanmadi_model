{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484aff72",
   "metadata": {},
   "source": [
    "# KoBART 기반 한국어 요약 자동화 및 평가 노트북\n",
    "\n",
    "이 노트북은 원본 데이터와 요약 데이터를 활용하여 KoBART 모델로 생성 요약을 수행하고, 업계 기준에 부합하는 종합 평가 점수(ROUGE 등)를 달성하기 위한 전처리, 파인튜닝, 평가까지의 전체 파이프라인을 자동화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb46e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rouge-score in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from rouge-score) (2.3.1)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from rouge-score) (2.3.2)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge-score) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge-score) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.0.tar.gz (2.6 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.2.0.tar.gz (2.6 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [48 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m2\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(compile('''\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "          \u001b[1;31m# This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
      "          \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<32 lines>...\n",
      "          \u001b[1;31mexec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
      "          \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          \u001b[1;31m''' % ('C:\\\\Users\\\\ritar\\\\AppData\\\\Local\\\\Temp\\\\pip-install-_phqgk87\\\\sentencepiece_e86a131d3e5d4cbb93ebe39cdf1b8ec5\\\\setup.py',), \"<pip-setuptools-caller>\", \"exec\"))\u001b[0m\n",
      "          \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<pip-setuptools-caller>\"\u001b[0m, line \u001b[35m35\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\ritar\\AppData\\Local\\Temp\\pip-install-_phqgk87\\sentencepiece_e86a131d3e5d4cbb93ebe39cdf1b8ec5\\setup.py\"\u001b[0m, line \u001b[35m128\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31msubprocess.check_call\u001b[0m\u001b[1;31m([\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "              \u001b[1;31m'cmake',\u001b[0m\n",
      "              \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "          ...<6 lines>...\n",
      "              \u001b[1;31m'-DCMAKE_INSTALL_PREFIX=build\\\\root',\u001b[0m\n",
      "              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          \u001b[1;31m])\u001b[0m\n",
      "          \u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\ProgramData\\anaconda3\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m414\u001b[0m, in \u001b[35mcheck_call\u001b[0m\n",
      "          retcode = call(*popenargs, **kwargs)\n",
      "        File \u001b[35m\"c:\\ProgramData\\anaconda3\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m395\u001b[0m, in \u001b[35mcall\u001b[0m\n",
      "          with \u001b[31mPopen\u001b[0m\u001b[1;31m(*popenargs, **kwargs)\u001b[0m as p:\n",
      "               \u001b[31m~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\ProgramData\\anaconda3\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1039\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "          \u001b[31mself._execute_child\u001b[0m\u001b[1;31m(args, executable, preexec_fn, close_fds,\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mpass_fds, cwd, env,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<5 lines>...\n",
      "                              \u001b[1;31mgid, gids, uid, umask,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mstart_new_session, process_group)\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\ProgramData\\anaconda3\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1554\u001b[0m, in \u001b[35m_execute_child\u001b[0m\n",
      "          hp, ht, pid, tid = \u001b[31m_winapi.CreateProcess\u001b[0m\u001b[1;31m(executable, args,\u001b[0m\n",
      "                             \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                                   \u001b[1;31m# no special security\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<4 lines>...\n",
      "                                   \u001b[1;31mcwd,\u001b[0m\n",
      "                                   \u001b[1;31m^^^^\u001b[0m\n",
      "                                   \u001b[1;31mstartupinfo)\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "      \u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m[WinError 2] 지정된 파일을 찾을 수 없습니다\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ritar\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 1. 환경 준비 및 필수 패키지 설치\n",
    "import sys\n",
    "\n",
    "\n",
    "def install(package):\n",
    "    import IPython\n",
    "\n",
    "    IPython.get_ipython().run_line_magic(\"pip\", f\"install {package}\")\n",
    "\n",
    "\n",
    "for p in [\n",
    "    \"transformers==4.21.0\",\n",
    "    \"torch>=1.13.0\",\n",
    "    \"datasets\",\n",
    "    \"evaluate\",\n",
    "    \"rouge-score\",\n",
    "    \"nltk\",\n",
    "    \"sentencepiece\",\n",
    "    \"scikit-learn\",\n",
    "    \"pandas\",\n",
    "    \"tqdm\",\n",
    "]:\n",
    "    try:\n",
    "        __import__(p.split(\"==\")[0].split(\">=\")[0])\n",
    "    except ImportError:\n",
    "        install(p)\n",
    "import pandas as pd, numpy as np, re, torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import Dataset\n",
    "import evaluate, nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1491b452",
   "metadata": {},
   "outputs": [
    {
     "ename": "PatternError",
     "evalue": "nothing to repeat at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPatternError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m originals, summaries \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_len):\n\u001b[1;32m---> 31\u001b[0m     o, s \u001b[38;5;241m=\u001b[39m preprocess(orig_df\u001b[38;5;241m.\u001b[39miloc[i][orig_col]), preprocess(summ_df\u001b[38;5;241m.\u001b[39miloc[i][summ_col])\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(o) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     33\u001b[0m         ow, sw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(o\u001b[38;5;241m.\u001b[39msplit()), \u001b[38;5;28mlen\u001b[39m(s\u001b[38;5;241m.\u001b[39msplit())\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(text)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m---> 15\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[0;32m     16\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[^가-힣]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\re\\__init__.py:208\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags, *args)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is passed as positional argument\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    206\u001b[0m     )\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msub(repl, string, count)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\re\\__init__.py:350\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _compiler\u001b[38;5;241m.\u001b[39misstring(pattern):\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst argument must be string or compiled pattern\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m p \u001b[38;5;241m=\u001b[39m _compiler\u001b[38;5;241m.\u001b[39mcompile(pattern, flags)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m DEBUG:\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\re\\_compiler.py:748\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 748\u001b[0m     p \u001b[38;5;241m=\u001b[39m _parser\u001b[38;5;241m.\u001b[39mparse(p, flags)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    750\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\re\\_parser.py:980\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    977\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[0;32m    978\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m--> 980\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    981\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\re\\_parser.py:459\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    457\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    460\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\re\\_parser.py:686\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    684\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m item \u001b[38;5;129;01mor\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m AT:\n\u001b[1;32m--> 686\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnothing to repeat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    687\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m here \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(this))\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _REPEATCODES:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiple repeat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    690\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m here \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(this))\n",
      "\u001b[1;31mPatternError\u001b[0m: nothing to repeat at position 0"
     ]
    }
   ],
   "source": [
    "# 2. 데이터 로드 및 전처리\n",
    "def safe_read_csv(path):\n",
    "    for enc in [\"utf-8-sig\", \"utf-8\", \"cp949\", \"euc-kr\"]:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except:\n",
    "            continue\n",
    "    raise ValueError(f\"CSV 파일 읽기 실패: {path}\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    if pd.isna(text) or not text:\n",
    "        return \"\"\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(r\"+\", \" \", text)\n",
    "    text = re.sub(r\"[^가-힣]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "orig_df = safe_read_csv(\"data/crawling_origin.csv\")\n",
    "summ_df = safe_read_csv(\"data/crawling_origin_with_summary.csv\")\n",
    "orig_col = next(\n",
    "    (c for c in orig_df.columns if \"본문\" in c or \"content\" in c), orig_df.columns[0]\n",
    ")\n",
    "summ_col = next(\n",
    "    (c for c in summ_df.columns if \"요약\" in c or \"summary\" in c), summ_df.columns[0]\n",
    ")\n",
    "min_len = min(len(orig_df), len(summ_df))\n",
    "originals, summaries = [], []\n",
    "for i in range(min_len):\n",
    "    o, s = preprocess(orig_df.iloc[i][orig_col]), preprocess(summ_df.iloc[i][summ_col])\n",
    "    if len(o) >= 20 and len(s) >= 3:\n",
    "        ow, sw = len(o.split()), len(s.split())\n",
    "        if ow > 0 and 0.01 <= sw / ow <= 0.8:\n",
    "            originals.append(o)\n",
    "            summaries.append(s)\n",
    "print(f\"유효 데이터: {len(originals)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 분할 및 Dataset 생성\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    originals, summaries, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input_text\"], max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"target_text\"], max_length=128, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gogamza/kobart-base-v2\")\n",
    "train_dataset = Dataset.from_dict({\"input_text\": X_train, \"target_text\": y_train}).map(\n",
    "    preprocess_function, batched=True\n",
    ")\n",
    "val_dataset = Dataset.from_dict({\"input_text\": X_val, \"target_text\": y_val}).map(\n",
    "    preprocess_function, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17272232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. KoBART 파인튜닝 (간단 Trainer)\n",
    "from transformers import (\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"gogamza/kobart-base-v2\").to(device)\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    return {k: v * 100 for k, v in result.items()}\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./kobart_finetuned\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=50,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=None,\n",
    ")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 평가 및 업계 기준 비교\n",
    "eval_result = trainer.evaluate()\n",
    "print(\"평가 결과:\", eval_result)\n",
    "print(\n",
    "    \"ROUGE-1:\",\n",
    "    eval_result.get(\"eval_rouge1\", 0),\n",
    "    \"ROUGE-2:\",\n",
    "    eval_result.get(\"eval_rouge2\", 0),\n",
    "    \"ROUGE-L:\",\n",
    "    eval_result.get(\"eval_rougeL\", 0),\n",
    ")\n",
    "# 업계 기준 예시: ROUGE-1 30~35% 이상이면 실무 적용 가능 수준\n",
    "if eval_result.get(\"eval_rouge1\", 0) >= 30:\n",
    "    print(\"✅ 업계 기준 도달!\")\n",
    "else:\n",
    "    print(\"⚠️ 업계 기준 미달. 데이터/전처리/파인튜닝 추가 필요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11bba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 실제 샘플 요약 및 비교\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(\n",
    "        device\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            **inputs, max_length=128, num_beams=3, early_stopping=True\n",
    "        )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"원본: {X_val[i][:100]}...\")\n",
    "    print(f\"실제요약: {y_val[i]}\")\n",
    "    print(f\"KoBART요약: {generate_summary(X_val[i])}\")\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
