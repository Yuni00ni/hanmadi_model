{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab89b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping torch as it is not installed.\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    }
   ],
   "source": [
    "# ⚡️ PyTorch GPU(CUDA) 버전 설치 안내\n",
    "\n",
    "# 아래 순서대로 실행하세요. 설치 후 반드시 커널을 재시작해야 GPU 버전이 적용됩니다.\n",
    "\n",
    "# 1. 기존 PyTorch, torchvision, torchaudio 삭제\n",
    "# 2. CUDA 12.1용 PyTorch 설치 (본인 CUDA 버전에 맞게)\n",
    "# 3. 커널 재시작 (필수!)\n",
    "# 4. torch import 후 GPU 인식 확인\n",
    "\n",
    "# - CUDA 드라이버와 Toolkit이 설치되어 있어야 합니다.\n",
    "# - 설치 후에도 CPU로만 동작하면, 드라이버/환경 문제일 수 있습니다.\n",
    "# - `nvidia-smi` 명령어로 GPU 인식 여부를 cmd에서 확인하세요.\n",
    "\n",
    "%pip uninstall -y torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a13cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n"
     ]
    }
   ],
   "source": [
    "# 🔧 PyTorch 설치 옵션들 (오류 발생 시 아래 옵션들을 순서대로 시도)\n",
    "\n",
    "# 옵션 1: CUDA 12.1 (최신)\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# 옵션 2: CUDA 11.8 (안정 버전) - 위 옵션이 안 되면 이걸 시도\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# 옵션 3: CPU 전용 (GPU 사용 불가능한 경우)\n",
    "# %pip install torch torchvision torchaudio\n",
    "\n",
    "# 옵션 4: conda 사용 (pip이 안 되는 경우)\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "print(\"설치 완료 후 반드시 커널을 재시작하세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9cfc88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 아래 셀로 GPU 인식 확인\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA 사용 가능:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 아래 셀로 GPU 인식 확인\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA 사용 가능:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU 이름:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA가 활성화되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9820cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 PyTorch, torchvision, torchaudio 삭제\n",
    "%pip uninstall -y torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 12.1용 PyTorch 설치 (권장)\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA 사용 가능:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU 이름:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA가 활성화되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-summarization')\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv('./data\\crawling_tuned_data.csv')\n",
    "\n",
    "print(f\"데이터 크기: {df.shape}\")\n",
    "print(f\"컬럼명: {list(df.columns)}\")\n",
    "print(\"\\n첫 번째 기사 제목:\")\n",
    "print(df['title'].iloc[0])\n",
    "print(\"\\n첫 번째 기사 본문 일부:\")\n",
    "print(df['text'].iloc[0][:200] + \"...\")\n",
    "\n",
    "text = \"과거를 떠올려보자. 방송을 보던 우리의 모습을. 독보적인 매체는 TV였다. 온 가족이 둘러앉아 TV를 봤다. 간혹 가족들끼리 뉴스와 드라마, 예능 프로그램을 둘러싸고 리모컨 쟁탈전이 벌어지기도  했다. 각자 선호하는 프로그램을 ‘본방’으로 보기 위한 싸움이었다. TV가 한 대인지 두 대인지 여부도 그래서 중요했다. 지금은 어떤가. ‘안방극장’이라는 말은 옛말이 됐다. TV가 없는 집도 많다. 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다. 각자의 방에서 각자의 휴대폰으로, 노트북으로, 태블릿으로 콘텐츠 를 즐긴다.\"\n",
    "\n",
    "raw_input_ids = tokenizer.encode(text)\n",
    "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "summary_ids = model.generate(torch.tensor([input_ids]))\n",
    "tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf97885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    \"\"\"\n",
    "    주어진 텍스트를 요약하는 함수\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or len(text.strip()) == 0:\n",
    "        return \"텍스트가 없습니다.\"\n",
    "    \n",
    "    # 텍스트가 너무 길면 일부만 사용 (토큰 제한 때문)\n",
    "    if len(text) > 2000:\n",
    "        text = text[:2000]\n",
    "    \n",
    "    try:\n",
    "        # 토큰화\n",
    "        raw_input_ids = tokenizer.encode(text)\n",
    "        input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "        \n",
    "        # 요약 생성\n",
    "        summary_ids = model.generate(torch.tensor([input_ids]), max_length=150, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "        \n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"요약 생성 중 오류 발생: {str(e)}\"\n",
    "\n",
    "# 첫 번째 기사 요약 테스트\n",
    "first_article = df['title'].iloc[0]\n",
    "print(\"원본 기사:\")\n",
    "print(first_article[:500] + \"...\")\n",
    "print(\"\\n요약:\")\n",
    "summary = summarize_text(first_article)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f143e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터로 여러 기사 요약 (처음 5개 기사)\n",
    "sample_size = 5\n",
    "sample_df = df.head(sample_size).copy()\n",
    "\n",
    "print(f\"{sample_size}개 기사 요약 중...\")\n",
    "summaries = []\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"기사 {idx + 1} 요약 중...\")\n",
    "    title = row['title']\n",
    "    content = row['text']\n",
    "    summary = summarize_text(content)\n",
    "    \n",
    "    summaries.append({\n",
    "        '원본_제목': title,\n",
    "        '요약': summary\n",
    "    })\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "summary_df = pd.DataFrame(summaries)\n",
    "\n",
    "# 결과 출력\n",
    "for i, row in summary_df.iterrows():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"기사 {i+1}\")\n",
    "    print(f\"제목: {row['원본_제목']}\")\n",
    "    print(f\"요약: {row['요약']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "# 요약 결과를 CSV로 저장\n",
    "summary_df.to_csv('./data/summaries_news.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n요약 결과가 'news_summaries.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2665a1",
   "metadata": {},
   "source": [
    "# 전체 데이터 요약 실행\n",
    "\n",
    "테스트가 완료되었으니 이제 전체 데이터셋에 대해 요약을 진행합니다.\n",
    "- GPU 사용 최적화\n",
    "- 배치 처리로 메모리 효율성 향상\n",
    "- 진행 상황 모니터링\n",
    "- 에러 처리 및 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e108a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 확인 및 디바이스 설정\n",
    "import time\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "print(\"🔍 시스템 환경 확인\")\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "\n",
    "# 디바이스 설정\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"🚀 GPU 사용: {gpu_name}\")\n",
    "    print(f\"💾 GPU 메모리: {gpu_memory:.1f}GB\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"🍎 Apple MPS GPU 사용\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    cpu_count = psutil.cpu_count()\n",
    "    ram_gb = psutil.virtual_memory().total / 1024**3\n",
    "    print(f\"💻 CPU 사용: {cpu_count}코어\")\n",
    "    print(f\"💾 RAM: {ram_gb:.1f}GB\")\n",
    "\n",
    "# 모델을 선택된 디바이스로 이동\n",
    "print(f\"\\n📦 모델을 {device}로 이동 중...\")\n",
    "model = model.to(device)\n",
    "print(\"✅ 모델 이동 완료\")\n",
    "\n",
    "# 메모리 사용량 확인\n",
    "if device.type == 'cuda':\n",
    "    allocated = torch.cuda.memory_allocated(device) / 1024**3\n",
    "    print(f\"💾 현재 GPU 메모리 사용량: {allocated:.2f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 처리를 위한 최적화된 요약 함수\n",
    "from tqdm import tqdm  # 진행 표시 라이브러리 import\n",
    "\n",
    "def summarize_batch(texts, batch_size=8, max_length=150):\n",
    "    \"\"\"\n",
    "    배치 단위로 텍스트 요약 처리 (GPU 최적화)\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(f\"📊 총 {len(texts)}개 기사 처리 시작\")\n",
    "    print(f\"⚙️ 배치 크기: {batch_size}\")\n",
    "    print(f\"🎯 디바이스: {device}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"요약 진행\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_summaries = []\n",
    "        \n",
    "        for text in batch_texts:\n",
    "            try:\n",
    "                # 텍스트 전처리\n",
    "                if pd.isna(text) or len(str(text).strip()) == 0:\n",
    "                    batch_summaries.append(\"텍스트가 없습니다.\")\n",
    "                    failed_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # 텍스트 길이 제한\n",
    "                text = str(text)\n",
    "                if len(text) > 2000:\n",
    "                    text = text[:2000]\n",
    "                \n",
    "                # 토큰화 및 디바이스 이동\n",
    "                raw_input_ids = tokenizer.encode(text, max_length=1024, truncation=True)\n",
    "                input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "                input_tensor = torch.tensor([input_ids]).to(device)\n",
    "                \n",
    "                # 요약 생성\n",
    "                with torch.no_grad():  # 메모리 절약\n",
    "                    summary_ids = model.generate(\n",
    "                        input_tensor,\n",
    "                        max_length=max_length,\n",
    "                        min_length=30,\n",
    "                        num_beams=4,\n",
    "                        early_stopping=True,\n",
    "                        no_repeat_ngram_size=2,\n",
    "                        length_penalty=1.0\n",
    "                    )\n",
    "                \n",
    "                # 디코딩\n",
    "                summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "                batch_summaries.append(summary)\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"요약 생성 실패: {str(e)[:100]}\"\n",
    "                batch_summaries.append(error_msg)\n",
    "                failed_count += 1\n",
    "                print(f\"⚠️ 기사 {i + len(batch_summaries)} 처리 중 오류: {e}\")\n",
    "        \n",
    "        summaries.extend(batch_summaries)\n",
    "        \n",
    "        # 메모리 정리 (매 10배치마다)\n",
    "        if i % (batch_size * 10) == 0:\n",
    "            gc.collect()\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "                allocated = torch.cuda.memory_allocated(device) / 1024**3\n",
    "                print(f\"💾 메모리 정리 후 GPU 사용량: {allocated:.2f}GB\")\n",
    "        \n",
    "        # 진행 상황 출력 (매 50배치마다)\n",
    "        if (i // batch_size + 1) % 50 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            processed = min(i + batch_size, len(texts))\n",
    "            rate = processed / elapsed\n",
    "            remaining = (len(texts) - processed) / rate / 60\n",
    "            print(f\"📈 진행: {processed}/{len(texts)} ({processed/len(texts)*100:.1f}%) - {rate:.1f}개/초 - 남은 시간: {remaining:.1f}분\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n✅ 요약 완료!\")\n",
    "    print(f\"⏱️ 총 처리 시간: {total_time/60:.1f}분\")\n",
    "    print(f\"⚡ 평균 처리 속도: {len(texts)/total_time:.1f}개/초\")\n",
    "    print(f\"❌ 실패한 기사: {failed_count}개\")\n",
    "    print(f\"✅ 성공률: {(len(texts)-failed_count)/len(texts)*100:.1f}%\")\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "print(\"🛠️ 배치 요약 함수 준비 완료 (tqdm 포함)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 확인 및 배치 크기 설정\n",
    "print(\"📊 전체 데이터 분석\")\n",
    "print(f\"총 기사 수: {len(df):,}개\")\n",
    "\n",
    "# 유효한 데이터만 필터링\n",
    "valid_data = df.dropna(subset=['text']).copy()\n",
    "valid_data = valid_data[valid_data['text'].str.len() > 50]  # 최소 50자 이상\n",
    "\n",
    "print(f\"유효한 기사: {len(valid_data):,}개\")\n",
    "print(f\"제거된 기사: {len(df) - len(valid_data):,}개\")\n",
    "\n",
    "# 텍스트 길이 분석\n",
    "text_lengths = valid_data['text'].str.len()\n",
    "print(f\"\\\\n📏 텍스트 길이 통계:\")\n",
    "print(f\"평균: {text_lengths.mean():.0f}자\")\n",
    "print(f\"중간값: {text_lengths.median():.0f}자\")\n",
    "print(f\"최대: {text_lengths.max():,}자\")\n",
    "print(f\"최소: {text_lengths.min():,}자\")\n",
    "\n",
    "# 디바이스별 배치 크기 설정\n",
    "if device.type == 'cuda':\n",
    "    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    if gpu_memory_gb >= 16:\n",
    "        batch_size = 16\n",
    "    elif gpu_memory_gb >= 8:\n",
    "        batch_size = 12\n",
    "    else:\n",
    "        batch_size = 8\n",
    "elif device.type == 'mps':\n",
    "    batch_size = 6  # MPS는 보수적으로\n",
    "else:\n",
    "    batch_size = 4  # CPU는 작은 배치\n",
    "\n",
    "print(f\"\\\\n⚙️ 설정된 배치 크기: {batch_size}\")\n",
    "\n",
    "# 예상 처리 시간 계산\n",
    "estimated_time = len(valid_data) / batch_size * 2  # 배치당 약 2초 가정\n",
    "print(f\"📅 예상 처리 시간: {estimated_time/60:.1f}분\")\n",
    "\n",
    "# 최종 확인\n",
    "print(f\"\\\\n🎯 처리 대상: {len(valid_data):,}개 기사\")\n",
    "print(f\"🔧 사용 디바이스: {device}\")\n",
    "print(f\"📦 배치 크기: {batch_size}\")\n",
    "\n",
    "# 데이터 준비\n",
    "df_to_process = valid_data.copy()\n",
    "print(\"\\\\n✅ 전체 데이터 처리 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 요약 실행 (GPU 최적화 및 길이 불일치 방지)\n",
    "print(\"🚀 전체 데이터 요약 시작!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 시작 전 메모리 상태 확인\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"💻 CUDA GPU 사용: {torch.cuda.get_device_name(0)}\")\n",
    "    initial_memory = torch.cuda.memory_allocated(device) / 1024**3\n",
    "    print(f\"💾 시작 전 GPU 메모리: {initial_memory:.2f}GB\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"🍎 Apple MPS GPU 사용\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"⚠️ CUDA GPU를 사용할 수 없습니다. CPU로 진행합니다. (Windows에서 NVIDIA GPU가 정상 설치되어 있는지 확인하세요)\")\n",
    "\n",
    "# 모델을 디바이스로 이동 (재확인)\n",
    "model = model.to(device)\n",
    "\n",
    "# 데이터 인덱스 초기화 및 텍스트 리스트 준비\n",
    "df_to_process = df_to_process.reset_index(drop=True)\n",
    "texts = df_to_process['text'].tolist()\n",
    "\n",
    "# 요약 실행\n",
    "try:\n",
    "    all_summaries = summarize_batch(\n",
    "        texts=texts,\n",
    "        batch_size=batch_size,\n",
    "        max_length=150\n",
    "    )\n",
    "\n",
    "    print(\"\\n📊 요약 결과 생성 중...\")\n",
    "\n",
    "    # 길이 불일치 방지: 요약 결과와 데이터 개수 맞추기\n",
    "    if len(all_summaries) != len(df_to_process):\n",
    "        print(f\"❗ 요약 결과 개수({len(all_summaries)})와 데이터 개수({len(df_to_process)})가 다릅니다. 맞춰서 저장합니다.\")\n",
    "        min_len = min(len(all_summaries), len(df_to_process))\n",
    "        df_to_process = df_to_process.iloc[:min_len].copy()\n",
    "        all_summaries = all_summaries[:min_len]\n",
    "\n",
    "    # 결과 DataFrame 생성\n",
    "    result_df = pd.DataFrame({\n",
    "        '기사_번호': range(1, len(df_to_process) + 1),\n",
    "        '원본_제목': df_to_process['title'].tolist(),\n",
    "        '원본_내용': df_to_process['text'].tolist(),\n",
    "        'KoBERT_요약': all_summaries,\n",
    "        '원본_길이': df_to_process['text'].str.len(),\n",
    "        '요약_길이': pd.Series(all_summaries).str.len(),\n",
    "    })\n",
    "\n",
    "    # 압축률 계산\n",
    "    result_df['압축률(%)'] = (result_df['요약_길이'] / result_df['원본_길이'] * 100).round(1)\n",
    "\n",
    "    # 요약 통계\n",
    "    print(f\"\\n📈 요약 통계:\")\n",
    "    print(f\"총 처리된 기사: {len(result_df):,}개\")\n",
    "    print(f\"평균 압축률: {result_df['압축률(%)'].mean():.1f}%\")\n",
    "    print(f\"평균 요약 길이: {result_df['요약_길이'].mean():.0f}자\")\n",
    "\n",
    "    # 실패한 요약 확인\n",
    "    failed_summaries = result_df[result_df['KoBERT_요약'].str.contains('실패|오류|없습니다')]\n",
    "    print(f\"실패한 요약: {len(failed_summaries)}개\")\n",
    "\n",
    "    print(\"\\n✅ 전체 데이터 요약 완료!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 요약 처리 중 오류 발생: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 요약 결과 저장\n",
    "try:\n",
    "    # 파일 경로 설정\n",
    "    output_path = '/data/kobert_full_news_summaries.csv'\n",
    "    \n",
    "    # CSV 파일로 저장\n",
    "    result_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"💾 결과 저장 완료!\")\n",
    "    print(f\"📁 파일 위치: {output_path}\")\n",
    "    print(f\"📊 저장된 데이터: {len(result_df):,}행 × {len(result_df.columns)}열\")\n",
    "    \n",
    "    # 파일 크기 확인\n",
    "    import os\n",
    "    file_size_mb = os.path.getsize(output_path) / 1024 / 1024\n",
    "    print(f\"📦 파일 크기: {file_size_mb:.1f}MB\")\n",
    "    \n",
    "    # 요약 품질 분석\n",
    "    print(f\"\\\\n📊 요약 품질 분석:\")\n",
    "    \n",
    "    # 압축률 분포\n",
    "    compression_ranges = [\n",
    "        (0, 10, \"매우 높은 압축\"),\n",
    "        (10, 20, \"높은 압축\"), \n",
    "        (20, 30, \"적절한 압축\"),\n",
    "        (30, 50, \"낮은 압축\"),\n",
    "        (50, 100, \"매우 낮은 압축\")\n",
    "    ]\n",
    "    \n",
    "    for min_val, max_val, label in compression_ranges:\n",
    "        count = len(result_df[(result_df['압축률(%)'] >= min_val) & (result_df['압축률(%)'] < max_val)])\n",
    "        percentage = count / len(result_df) * 100\n",
    "        print(f\"  {label} ({min_val}-{max_val}%): {count:,}개 ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\\\n📈 전체 통계:\")\n",
    "    print(result_df[['원본_길이', '요약_길이', '압축률(%)']].describe())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 결과 저장 중 오류: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b083cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 결과 샘플 확인\n",
    "print(\"🔍 요약 결과 샘플 확인 (무작위 3개)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 무작위로 3개 샘플 선택\n",
    "import random\n",
    "sample_indices = random.sample(range(len(result_df)), min(3, len(result_df)))\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    row = result_df.iloc[idx]\n",
    "    print(f\"\\\\n📰 샘플 {i} (기사 번호: {row['기사_번호']})\")\n",
    "    print(f\"제목: {row['원본_제목'][:100]}...\")\n",
    "    print(f\"원본 ({row['원본_길이']}자): {row['원본_내용'][:200]}...\")\n",
    "    print(f\"요약 ({row['요약_길이']}자): {row['KoBERT_요약']}\")\n",
    "    print(f\"압축률: {row['압축률(%)']}%\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# 최고/최저 압축률 기사 확인\n",
    "print(f\"\\\\n🏆 압축률 극값 사례:\")\n",
    "best_compression = result_df.loc[result_df['압축률(%)'].idxmin()]\n",
    "worst_compression = result_df.loc[result_df['압축률(%)'].idxmax()]\n",
    "\n",
    "print(f\"\\\\n📉 최고 압축 (압축률: {best_compression['압축률(%)']}%):\")\n",
    "print(f\"제목: {best_compression['원본_제목'][:100]}...\")\n",
    "print(f\"요약: {best_compression['KoBERT_요약']}\")\n",
    "\n",
    "print(f\"\\\\n📈 최저 압축 (압축률: {worst_compression['압축률(%)']}%):\")\n",
    "print(f\"제목: {worst_compression['원본_제목'][:100]}...\")\n",
    "print(f\"요약: {worst_compression['KoBERT_요약']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02906ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 정리 및 작업 완료\n",
    "print(\"\\\\n🧹 메모리 정리 중...\")\n",
    "\n",
    "# 메모리 정리\n",
    "gc.collect()\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    final_memory = torch.cuda.memory_allocated(device) / 1024**3\n",
    "    max_memory = torch.cuda.max_memory_allocated(device) / 1024**3\n",
    "    print(f\"💾 최종 GPU 메모리 사용량: {final_memory:.2f}GB\")\n",
    "    print(f\"💾 최대 GPU 메모리 사용량: {max_memory:.2f}GB\")\n",
    "\n",
    "# 최종 완료 메시지\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"🎉 전체 뉴스 데이터 KoBERT 요약 완료!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✅ 처리된 기사 수: {len(result_df):,}개\")\n",
    "print(f\"📁 결과 파일: kobert_full_news_summaries.csv\")\n",
    "print(f\"📊 평균 압축률: {result_df['압축률(%)'].mean():.1f}%\")\n",
    "print(f\"⏱️ 사용된 디바이스: {device}\")\n",
    "print(\"\\\\n다음 단계:\")\n",
    "print(\"1. 저장된 CSV 파일을 확인하세요\")\n",
    "print(\"2. 필요시 요약 품질 평가를 진행하세요\")\n",
    "print(\"3. 원본 데이터와 요약 데이터를 비교 분석하세요\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
