{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ab89b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.13/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.13/site-packages (2.7.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.13/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (1.1.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (1.1.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4118b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: (10952, 3)\n",
      "컬럼명: ['original_url', 'title', 'text']\n",
      "\n",
      "첫 번째 기사 제목:\n",
      "이 대통령, 6개 시군 특별재난 지역 선포 “재난에 음주가무 엄히 단속”\n",
      "\n",
      "첫 번째 기사 본문 일부:\n",
      "이재명 대통령이 경기도 가평과 전남 담양, 경남 산청 등 6개 시군을 특별재난지역으로 선포했습니다.   이 대통령은 재난 상황에서 부적절한 공직자들의 처신 문제도 거론했는데, 엄혹한 현장에서 음주가무를 즐기는 정신 나간 경우도 있었다며 엄히 단속하라고 주문했습니다.   보도에 이희연 기자입니다.   리포트  경기도 가평과 충남 서산 예산.....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TV가 없는 집도 많아지고 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-summarization')\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv('/Volumes/1TB/스인재/esgc team project/data/crawling_tuned_data.csv')\n",
    "\n",
    "print(f\"데이터 크기: {df.shape}\")\n",
    "print(f\"컬럼명: {list(df.columns)}\")\n",
    "print(\"\\n첫 번째 기사 제목:\")\n",
    "print(df['title'].iloc[0])\n",
    "print(\"\\n첫 번째 기사 본문 일부:\")\n",
    "print(df['text'].iloc[0][:200] + \"...\")\n",
    "\n",
    "text = \"과거를 떠올려보자. 방송을 보던 우리의 모습을. 독보적인 매체는 TV였다. 온 가족이 둘러앉아 TV를 봤다. 간혹 가족들끼리 뉴스와 드라마, 예능 프로그램을 둘러싸고 리모컨 쟁탈전이 벌어지기도  했다. 각자 선호하는 프로그램을 ‘본방’으로 보기 위한 싸움이었다. TV가 한 대인지 두 대인지 여부도 그래서 중요했다. 지금은 어떤가. ‘안방극장’이라는 말은 옛말이 됐다. TV가 없는 집도 많다. 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다. 각자의 방에서 각자의 휴대폰으로, 노트북으로, 태블릿으로 콘텐츠 를 즐긴다.\"\n",
    "\n",
    "raw_input_ids = tokenizer.encode(text)\n",
    "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "summary_ids = model.generate(torch.tensor([input_ids]))\n",
    "tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf97885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 기사:\n",
      "이 대통령, 6개 시군 특별재난 지역 선포 “재난에 음주가무 엄히 단속”...\n",
      "\n",
      "요약:\n",
      "이 대통령, 6개 시군 특별재난 지역 선포 “재난에 음주가무 엄히 단속”\n",
      "이 대통령, 6개 시군 특별재난 지역 선포 “재난에 음주가무 엄히 단속”\n"
     ]
    }
   ],
   "source": [
    "def summarize_text(text):\n",
    "    \"\"\"\n",
    "    주어진 텍스트를 요약하는 함수\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or len(text.strip()) == 0:\n",
    "        return \"텍스트가 없습니다.\"\n",
    "    \n",
    "    # 텍스트가 너무 길면 일부만 사용 (토큰 제한 때문)\n",
    "    if len(text) > 2000:\n",
    "        text = text[:2000]\n",
    "    \n",
    "    try:\n",
    "        # 토큰화\n",
    "        raw_input_ids = tokenizer.encode(text)\n",
    "        input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "        \n",
    "        # 요약 생성\n",
    "        summary_ids = model.generate(torch.tensor([input_ids]), max_length=150, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)\n",
    "        \n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"요약 생성 중 오류 발생: {str(e)}\"\n",
    "\n",
    "# 첫 번째 기사 요약 테스트\n",
    "first_article = df['title'].iloc[0]\n",
    "print(\"원본 기사:\")\n",
    "print(first_article[:500] + \"...\")\n",
    "print(\"\\n요약:\")\n",
    "summary = summarize_text(first_article)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f143e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5개 기사 요약 중...\n",
      "기사 1 요약 중...\n",
      "기사 2 요약 중...\n",
      "기사 2 요약 중...\n",
      "기사 3 요약 중...\n",
      "기사 3 요약 중...\n",
      "기사 4 요약 중...\n",
      "기사 4 요약 중...\n",
      "기사 5 요약 중...\n",
      "기사 5 요약 중...\n",
      "\n",
      "==================================================\n",
      "기사 1\n",
      "제목: 이 대통령, 6개 시군 특별재난 지역 선포 “재난에 음주가무 엄히 단속”\n",
      "요약: 이재명 대통령이 경기도 가평과 전남 담양, 경남 산청 등 6개 시군을 특별재난지역으로 선포하고 엄정한 단속을 주문했다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "기사 2\n",
      "제목: 신경호 결심 공판 열려 검찰 “징역 3년 요구”\n",
      "요약: 신경호 강원도교육감에 대한 결심공판이 어제22일 열렸는데   검찰은 징역형을 내려야한다고 주장했고   신경호 강원도교육감이 나타납니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "기사 3\n",
      "제목: ‘계엄 옹호’ 강준욱 자진 사퇴 최동석 ‘2차 가해’ 발언 등 논란 확산\n",
      "요약: 강준욱 대통령실 국민통합비서관이 계엄 옹호 발언 등으로 결국 자진 사퇴했고, 최동석 인사혁신처장도 박원순 전 시장 사건을 두고 한 과거 발언이 2차 가해 논란에 섰다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "기사 4\n",
      "제목: 이 대통령, 강선우 등 4명 청문보고서 재송부 요청\n",
      "요약: 이재명 대통령은 국회에 강선우 여성가족부 장관 후보자를 포함해, 국방부와 국가보훈부, 통일부 장관 후보자에 대한 인사청문보고서를 내일까지 재송부해 달라고 요청했고  강유정 대통령실 대변인은 브리핑을 통해 이번주 내 임명을 마무리하고 신속한 국정 안정을 꾀하기 위해 기한은 오는 24일로 요청했다고 밝혔다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "기사 5\n",
      "제목: 6곳 특별재난지역 선포 “공직자 부적절 행위 엄히 단속”\n",
      "요약: 중앙재난안전대책본부는 경기 가평, 충남 서산 예산, 전남 담양, 경남 산청 합천을 집중호우 피해지역에 대한 사전조사를 토대로 대통령 재가를 받아 특별재난지역으로 우선 선포했다고 밝혔다.\n",
      "==================================================\n",
      "\n",
      "요약 결과가 'news_summaries.csv' 파일로 저장되었습니다.\n",
      "\n",
      "==================================================\n",
      "기사 1\n",
      "제목: 이 대통령, 6개 시군 특별재난 지역 선포 “재난에 음주가무 엄히 단속”\n",
      "요약: 이재명 대통령이 경기도 가평과 전남 담양, 경남 산청 등 6개 시군을 특별재난지역으로 선포하고 엄정한 단속을 주문했다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "기사 2\n",
      "제목: 신경호 결심 공판 열려 검찰 “징역 3년 요구”\n",
      "요약: 신경호 강원도교육감에 대한 결심공판이 어제22일 열렸는데   검찰은 징역형을 내려야한다고 주장했고   신경호 강원도교육감이 나타납니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "기사 3\n",
      "제목: ‘계엄 옹호’ 강준욱 자진 사퇴 최동석 ‘2차 가해’ 발언 등 논란 확산\n",
      "요약: 강준욱 대통령실 국민통합비서관이 계엄 옹호 발언 등으로 결국 자진 사퇴했고, 최동석 인사혁신처장도 박원순 전 시장 사건을 두고 한 과거 발언이 2차 가해 논란에 섰다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "기사 4\n",
      "제목: 이 대통령, 강선우 등 4명 청문보고서 재송부 요청\n",
      "요약: 이재명 대통령은 국회에 강선우 여성가족부 장관 후보자를 포함해, 국방부와 국가보훈부, 통일부 장관 후보자에 대한 인사청문보고서를 내일까지 재송부해 달라고 요청했고  강유정 대통령실 대변인은 브리핑을 통해 이번주 내 임명을 마무리하고 신속한 국정 안정을 꾀하기 위해 기한은 오는 24일로 요청했다고 밝혔다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "기사 5\n",
      "제목: 6곳 특별재난지역 선포 “공직자 부적절 행위 엄히 단속”\n",
      "요약: 중앙재난안전대책본부는 경기 가평, 충남 서산 예산, 전남 담양, 경남 산청 합천을 집중호우 피해지역에 대한 사전조사를 토대로 대통령 재가를 받아 특별재난지역으로 우선 선포했다고 밝혔다.\n",
      "==================================================\n",
      "\n",
      "요약 결과가 'news_summaries.csv' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 샘플 데이터로 여러 기사 요약 (처음 5개 기사)\n",
    "sample_size = 5\n",
    "sample_df = df.head(sample_size).copy()\n",
    "\n",
    "print(f\"{sample_size}개 기사 요약 중...\")\n",
    "summaries = []\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"기사 {idx + 1} 요약 중...\")\n",
    "    title = row['title']\n",
    "    content = row['text']\n",
    "    summary = summarize_text(content)\n",
    "    \n",
    "    summaries.append({\n",
    "        '원본_제목': title,\n",
    "        '요약': summary\n",
    "    })\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "summary_df = pd.DataFrame(summaries)\n",
    "\n",
    "# 결과 출력\n",
    "for i, row in summary_df.iterrows():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"기사 {i+1}\")\n",
    "    print(f\"제목: {row['원본_제목']}\")\n",
    "    print(f\"요약: {row['요약']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "# 요약 결과를 CSV로 저장\n",
    "summary_df.to_csv('/Volumes/1TB/스인재/esgc team project/news_summaries.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n요약 결과가 'news_summaries.csv' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2665a1",
   "metadata": {},
   "source": [
    "# 전체 데이터 요약 실행\n",
    "\n",
    "테스트가 완료되었으니 이제 전체 데이터셋에 대해 요약을 진행합니다.\n",
    "- GPU 사용 최적화\n",
    "- 배치 처리로 메모리 효율성 향상\n",
    "- 진행 상황 모니터링\n",
    "- 에러 처리 및 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e108a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 시스템 환경 확인\n",
      "PyTorch 버전: 2.7.1\n",
      "CUDA 사용 가능: False\n",
      "🍎 Apple MPS GPU 사용\n",
      "\n",
      "📦 모델을 mps로 이동 중...\n",
      "✅ 모델 이동 완료\n",
      "✅ 모델 이동 완료\n"
     ]
    }
   ],
   "source": [
    "# GPU 확인 및 디바이스 설정\n",
    "import time\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "print(\"🔍 시스템 환경 확인\")\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "\n",
    "# 디바이스 설정\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"🚀 GPU 사용: {gpu_name}\")\n",
    "    print(f\"💾 GPU 메모리: {gpu_memory:.1f}GB\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"🍎 Apple MPS GPU 사용\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    cpu_count = psutil.cpu_count()\n",
    "    ram_gb = psutil.virtual_memory().total / 1024**3\n",
    "    print(f\"💻 CPU 사용: {cpu_count}코어\")\n",
    "    print(f\"💾 RAM: {ram_gb:.1f}GB\")\n",
    "\n",
    "# 모델을 선택된 디바이스로 이동\n",
    "print(f\"\\n📦 모델을 {device}로 이동 중...\")\n",
    "model = model.to(device)\n",
    "print(\"✅ 모델 이동 완료\")\n",
    "\n",
    "# 메모리 사용량 확인\n",
    "if device.type == 'cuda':\n",
    "    allocated = torch.cuda.memory_allocated(device) / 1024**3\n",
    "    print(f\"💾 현재 GPU 메모리 사용량: {allocated:.2f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7699e2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ 배치 요약 함수 준비 완료 (tqdm 포함)\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 처리를 위한 최적화된 요약 함수\n",
    "from tqdm import tqdm  # 진행 표시 라이브러리 import\n",
    "\n",
    "def summarize_batch(texts, batch_size=8, max_length=150):\n",
    "    \"\"\"\n",
    "    배치 단위로 텍스트 요약 처리 (GPU 최적화)\n",
    "    \"\"\"\n",
    "    summaries = []\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(f\"📊 총 {len(texts)}개 기사 처리 시작\")\n",
    "    print(f\"⚙️ 배치 크기: {batch_size}\")\n",
    "    print(f\"🎯 디바이스: {device}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"요약 진행\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_summaries = []\n",
    "        \n",
    "        for text in batch_texts:\n",
    "            try:\n",
    "                # 텍스트 전처리\n",
    "                if pd.isna(text) or len(str(text).strip()) == 0:\n",
    "                    batch_summaries.append(\"텍스트가 없습니다.\")\n",
    "                    failed_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # 텍스트 길이 제한\n",
    "                text = str(text)\n",
    "                if len(text) > 2000:\n",
    "                    text = text[:2000]\n",
    "                \n",
    "                # 토큰화 및 디바이스 이동\n",
    "                raw_input_ids = tokenizer.encode(text, max_length=1024, truncation=True)\n",
    "                input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "                input_tensor = torch.tensor([input_ids]).to(device)\n",
    "                \n",
    "                # 요약 생성\n",
    "                with torch.no_grad():  # 메모리 절약\n",
    "                    summary_ids = model.generate(\n",
    "                        input_tensor,\n",
    "                        max_length=max_length,\n",
    "                        min_length=30,\n",
    "                        num_beams=4,\n",
    "                        early_stopping=True,\n",
    "                        no_repeat_ngram_size=2,\n",
    "                        length_penalty=1.0\n",
    "                    )\n",
    "                \n",
    "                # 디코딩\n",
    "                summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "                batch_summaries.append(summary)\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"요약 생성 실패: {str(e)[:100]}\"\n",
    "                batch_summaries.append(error_msg)\n",
    "                failed_count += 1\n",
    "                print(f\"⚠️ 기사 {i + len(batch_summaries)} 처리 중 오류: {e}\")\n",
    "        \n",
    "        summaries.extend(batch_summaries)\n",
    "        \n",
    "        # 메모리 정리 (매 10배치마다)\n",
    "        if i % (batch_size * 10) == 0:\n",
    "            gc.collect()\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "                allocated = torch.cuda.memory_allocated(device) / 1024**3\n",
    "                print(f\"💾 메모리 정리 후 GPU 사용량: {allocated:.2f}GB\")\n",
    "        \n",
    "        # 진행 상황 출력 (매 50배치마다)\n",
    "        if (i // batch_size + 1) % 50 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            processed = min(i + batch_size, len(texts))\n",
    "            rate = processed / elapsed\n",
    "            remaining = (len(texts) - processed) / rate / 60\n",
    "            print(f\"📈 진행: {processed}/{len(texts)} ({processed/len(texts)*100:.1f}%) - {rate:.1f}개/초 - 남은 시간: {remaining:.1f}분\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n✅ 요약 완료!\")\n",
    "    print(f\"⏱️ 총 처리 시간: {total_time/60:.1f}분\")\n",
    "    print(f\"⚡ 평균 처리 속도: {len(texts)/total_time:.1f}개/초\")\n",
    "    print(f\"❌ 실패한 기사: {failed_count}개\")\n",
    "    print(f\"✅ 성공률: {(len(texts)-failed_count)/len(texts)*100:.1f}%\")\n",
    "    \n",
    "    return summaries\n",
    "\n",
    "print(\"🛠️ 배치 요약 함수 준비 완료 (tqdm 포함)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19ad181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 전체 데이터 분석\n",
      "총 기사 수: 10,952개\n",
      "유효한 기사: 10,812개\n",
      "제거된 기사: 140개\n",
      "\\n📏 텍스트 길이 통계:\n",
      "평균: 189자\n",
      "중간값: 190자\n",
      "최대: 200자\n",
      "최소: 52자\n",
      "\\n⚙️ 설정된 배치 크기: 6\n",
      "📅 예상 처리 시간: 60.1분\n",
      "\\n🎯 처리 대상: 10,812개 기사\n",
      "🔧 사용 디바이스: mps\n",
      "📦 배치 크기: 6\n",
      "\\n✅ 전체 데이터 처리 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 확인 및 배치 크기 설정\n",
    "print(\"📊 전체 데이터 분석\")\n",
    "print(f\"총 기사 수: {len(df):,}개\")\n",
    "\n",
    "# 유효한 데이터만 필터링\n",
    "valid_data = df.dropna(subset=['text']).copy()\n",
    "valid_data = valid_data[valid_data['text'].str.len() > 50]  # 최소 50자 이상\n",
    "\n",
    "print(f\"유효한 기사: {len(valid_data):,}개\")\n",
    "print(f\"제거된 기사: {len(df) - len(valid_data):,}개\")\n",
    "\n",
    "# 텍스트 길이 분석\n",
    "text_lengths = valid_data['text'].str.len()\n",
    "print(f\"\\\\n📏 텍스트 길이 통계:\")\n",
    "print(f\"평균: {text_lengths.mean():.0f}자\")\n",
    "print(f\"중간값: {text_lengths.median():.0f}자\")\n",
    "print(f\"최대: {text_lengths.max():,}자\")\n",
    "print(f\"최소: {text_lengths.min():,}자\")\n",
    "\n",
    "# 디바이스별 배치 크기 설정\n",
    "if device.type == 'cuda':\n",
    "    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    if gpu_memory_gb >= 16:\n",
    "        batch_size = 16\n",
    "    elif gpu_memory_gb >= 8:\n",
    "        batch_size = 12\n",
    "    else:\n",
    "        batch_size = 8\n",
    "elif device.type == 'mps':\n",
    "    batch_size = 6  # MPS는 보수적으로\n",
    "else:\n",
    "    batch_size = 4  # CPU는 작은 배치\n",
    "\n",
    "print(f\"\\\\n⚙️ 설정된 배치 크기: {batch_size}\")\n",
    "\n",
    "# 예상 처리 시간 계산\n",
    "estimated_time = len(valid_data) / batch_size * 2  # 배치당 약 2초 가정\n",
    "print(f\"📅 예상 처리 시간: {estimated_time/60:.1f}분\")\n",
    "\n",
    "# 최종 확인\n",
    "print(f\"\\\\n🎯 처리 대상: {len(valid_data):,}개 기사\")\n",
    "print(f\"🔧 사용 디바이스: {device}\")\n",
    "print(f\"📦 배치 크기: {batch_size}\")\n",
    "\n",
    "# 데이터 준비\n",
    "df_to_process = valid_data.copy()\n",
    "print(\"\\\\n✅ 전체 데이터 처리 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 전체 데이터 요약 시작!\n",
      "============================================================\n",
      "📊 총 10812개 기사 처리 시작\n",
      "⚙️ 배치 크기: 6\n",
      "🎯 디바이스: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "요약 진행:   1%|          | 20/1802 [04:45<7:42:48, 15.58s/it]"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 요약 실행\n",
    "print(\"🚀 전체 데이터 요약 시작!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 시작 전 메모리 상태 확인\n",
    "if device.type == 'cuda':\n",
    "    initial_memory = torch.cuda.memory_allocated(device) / 1024**3\n",
    "    print(f\"💾 시작 전 GPU 메모리: {initial_memory:.2f}GB\")\n",
    "\n",
    "# 요약 실행\n",
    "try:\n",
    "    all_summaries = summarize_batch(\n",
    "        texts=df_to_process['text'].tolist(),\n",
    "        batch_size=batch_size,\n",
    "        max_length=150\n",
    "    )\n",
    "    \n",
    "    print(\"\\\\n📊 요약 결과 생성 중...\")\n",
    "    \n",
    "    # 결과 DataFrame 생성\n",
    "    result_df = pd.DataFrame({\n",
    "        '기사_번호': range(1, len(df_to_process) + 1),\n",
    "        '원본_제목': df_to_process['title'].tolist(),\n",
    "        '원본_내용': df_to_process['text'].tolist(),\n",
    "        'KoBERT_요약': all_summaries,\n",
    "        '원본_길이': df_to_process['text'].str.len(),\n",
    "        '요약_길이': pd.Series(all_summaries).str.len(),\n",
    "    })\n",
    "    \n",
    "    # 압축률 계산\n",
    "    result_df['압축률(%)'] = (result_df['요약_길이'] / result_df['원본_길이'] * 100).round(1)\n",
    "    \n",
    "    # 요약 통계\n",
    "    print(f\"\\\\n📈 요약 통계:\")\n",
    "    print(f\"총 처리된 기사: {len(result_df):,}개\")\n",
    "    print(f\"평균 압축률: {result_df['압축률(%)'].mean():.1f}%\")\n",
    "    print(f\"평균 요약 길이: {result_df['요약_길이'].mean():.0f}자\")\n",
    "    \n",
    "    # 실패한 요약 확인\n",
    "    failed_summaries = result_df[result_df['KoBERT_요약'].str.contains('실패|오류|없습니다')]\n",
    "    print(f\"실패한 요약: {len(failed_summaries)}개\")\n",
    "    \n",
    "    print(\"\\\\n✅ 전체 데이터 요약 완료!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 요약 처리 중 오류 발생: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 요약 결과 저장\n",
    "try:\n",
    "    # 파일 경로 설정\n",
    "    output_path = '/Volumes/1TB/스인재/esgc team project/kobert_full_news_summaries.csv'\n",
    "    \n",
    "    # CSV 파일로 저장\n",
    "    result_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"💾 결과 저장 완료!\")\n",
    "    print(f\"📁 파일 위치: {output_path}\")\n",
    "    print(f\"📊 저장된 데이터: {len(result_df):,}행 × {len(result_df.columns)}열\")\n",
    "    \n",
    "    # 파일 크기 확인\n",
    "    import os\n",
    "    file_size_mb = os.path.getsize(output_path) / 1024 / 1024\n",
    "    print(f\"📦 파일 크기: {file_size_mb:.1f}MB\")\n",
    "    \n",
    "    # 요약 품질 분석\n",
    "    print(f\"\\\\n📊 요약 품질 분석:\")\n",
    "    \n",
    "    # 압축률 분포\n",
    "    compression_ranges = [\n",
    "        (0, 10, \"매우 높은 압축\"),\n",
    "        (10, 20, \"높은 압축\"), \n",
    "        (20, 30, \"적절한 압축\"),\n",
    "        (30, 50, \"낮은 압축\"),\n",
    "        (50, 100, \"매우 낮은 압축\")\n",
    "    ]\n",
    "    \n",
    "    for min_val, max_val, label in compression_ranges:\n",
    "        count = len(result_df[(result_df['압축률(%)'] >= min_val) & (result_df['압축률(%)'] < max_val)])\n",
    "        percentage = count / len(result_df) * 100\n",
    "        print(f\"  {label} ({min_val}-{max_val}%): {count:,}개 ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\\\n📈 전체 통계:\")\n",
    "    print(result_df[['원본_길이', '요약_길이', '압축률(%)']].describe())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 결과 저장 중 오류: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b083cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 결과 샘플 확인\n",
    "print(\"🔍 요약 결과 샘플 확인 (무작위 3개)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 무작위로 3개 샘플 선택\n",
    "import random\n",
    "sample_indices = random.sample(range(len(result_df)), min(3, len(result_df)))\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    row = result_df.iloc[idx]\n",
    "    print(f\"\\\\n📰 샘플 {i} (기사 번호: {row['기사_번호']})\")\n",
    "    print(f\"제목: {row['원본_제목'][:100]}...\")\n",
    "    print(f\"원본 ({row['원본_길이']}자): {row['원본_내용'][:200]}...\")\n",
    "    print(f\"요약 ({row['요약_길이']}자): {row['KoBERT_요약']}\")\n",
    "    print(f\"압축률: {row['압축률(%)']}%\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# 최고/최저 압축률 기사 확인\n",
    "print(f\"\\\\n🏆 압축률 극값 사례:\")\n",
    "best_compression = result_df.loc[result_df['압축률(%)'].idxmin()]\n",
    "worst_compression = result_df.loc[result_df['압축률(%)'].idxmax()]\n",
    "\n",
    "print(f\"\\\\n📉 최고 압축 (압축률: {best_compression['압축률(%)']}%):\")\n",
    "print(f\"제목: {best_compression['원본_제목'][:100]}...\")\n",
    "print(f\"요약: {best_compression['KoBERT_요약']}\")\n",
    "\n",
    "print(f\"\\\\n📈 최저 압축 (압축률: {worst_compression['압축률(%)']}%):\")\n",
    "print(f\"제목: {worst_compression['원본_제목'][:100]}...\")\n",
    "print(f\"요약: {worst_compression['KoBERT_요약']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02906ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 정리 및 작업 완료\n",
    "print(\"\\\\n🧹 메모리 정리 중...\")\n",
    "\n",
    "# 메모리 정리\n",
    "gc.collect()\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    final_memory = torch.cuda.memory_allocated(device) / 1024**3\n",
    "    max_memory = torch.cuda.max_memory_allocated(device) / 1024**3\n",
    "    print(f\"💾 최종 GPU 메모리 사용량: {final_memory:.2f}GB\")\n",
    "    print(f\"💾 최대 GPU 메모리 사용량: {max_memory:.2f}GB\")\n",
    "\n",
    "# 최종 완료 메시지\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"🎉 전체 뉴스 데이터 KoBERT 요약 완료!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✅ 처리된 기사 수: {len(result_df):,}개\")\n",
    "print(f\"📁 결과 파일: kobert_full_news_summaries.csv\")\n",
    "print(f\"📊 평균 압축률: {result_df['압축률(%)'].mean():.1f}%\")\n",
    "print(f\"⏱️ 사용된 디바이스: {device}\")\n",
    "print(\"\\\\n다음 단계:\")\n",
    "print(\"1. 저장된 CSV 파일을 확인하세요\")\n",
    "print(\"2. 필요시 요약 품질 평가를 진행하세요\")\n",
    "print(\"3. 원본 데이터와 요약 데이터를 비교 분석하세요\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
