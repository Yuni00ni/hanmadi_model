{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f9836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.13/site-packages (5.0.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ✅ KoSentenceBERT 기반 의미 유사도 평가 코드\n",
    "# 설치 (최초 1회만 필요)\n",
    "%pip install sentence-transformers pandas\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36eef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍎 Mac GPU (MPS)를 사용합니다\n",
      "선택된 디바이스: mps\n",
      "✅ 모델을 mps로 이동완료\n",
      "merged_df 크기: (10952, 9)\n",
      "original_df 크기: (10952, 19)\n"
     ]
    }
   ],
   "source": [
    "# ✅ 1. 모델 로드 (한국어 SBERT)\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Mac GPU (MPS) 사용 설정\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"🍎 Mac GPU (MPS)를 사용합니다\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"🚀 NVIDIA GPU (CUDA)를 사용합니다\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"💻 CPU를 사용합니다\")\n",
    "\n",
    "print(f\"선택된 디바이스: {device}\")\n",
    "\n",
    "# 모델 로드 및 디바이스 이동\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "try:\n",
    "    model = model.to(device)\n",
    "    print(f\"✅ 모델을 {device}로 이동완료\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ {device} 사용 중 오류 발생: {e}\")\n",
    "    device = 'cpu'\n",
    "    model = model.to(device)\n",
    "    print(\"🔄 CPU로 fallback\")\n",
    "\n",
    "# ✅ 2. 데이터 불러오기\n",
    "merged_df = pd.read_csv(\"merged_news_data (3).csv\")\n",
    "original_df = pd.read_csv(\"NewsResult_2025뉴스.xlsx - sheet.csv\")\n",
    "\n",
    "print(f\"merged_df 크기: {merged_df.shape}\")\n",
    "print(f\"original_df 크기: {original_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17ffd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합된 데이터 크기: (271748, 27)\n",
      "요약문 개수: 271748, 원문 개수: 271748\n",
      "\n",
      "첫 번째 요약문 예시:\n",
      "이재명 대통령은 경기도 가평과 충남 서산·예산, 전남 담양, 경남 산청·합천 등 6개 시군을 특별재난지역으로 선포했는데, 엄혹한 현장에서 음주가무를 즐기는 공직자들의 처신 문제도 거론했다.\n",
      "\n",
      "첫 번째 원문 예시:\n",
      "[앵커]\n",
      "\n",
      " 이재명 대통령이 경기도 가평과 전남 담양, 경남 산청 등 6개 시군을 특별재난지역으로 선포했습니다.\n",
      "\n",
      " 이 대통령은 재난 상황에서 부적절한 공직자들의 처신 문제도 거론했는데, 엄혹한 현장에서 음주가무를 즐기는 정신 나간 경우도 있었다며 엄히 단속하라고 주문했습니다.\n",
      "\n",
      " 보도에 이희연 기자입니다.\n",
      "\n",
      " [리포트]\n",
      "\n",
      "경기도 가평과 충남 서산 예산..\n"
     ]
    }
   ],
   "source": [
    "# ✅ 3. 데이터 병합 및 준비\n",
    "data = pd.merge(merged_df, original_df, on='뉴스 식별자')\n",
    "summaries = data['요약문'].astype(str).tolist()\n",
    "originals = data['본문'].astype(str).tolist()\n",
    "\n",
    "print(f\"병합된 데이터 크기: {data.shape}\")\n",
    "print(f\"요약문 개수: {len(summaries)}, 원문 개수: {len(originals)}\")\n",
    "\n",
    "# 첫 번째 요약문과 원문 예시 확인\n",
    "print(\"\\n첫 번째 요약문 예시:\")\n",
    "print(summaries[0][:200] + \"...\" if len(summaries[0]) > 200 else summaries[0])\n",
    "print(\"\\n첫 번째 원문 예시:\")\n",
    "print(originals[0][:200] + \"...\" if len(originals[0]) > 200 else originals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04106ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 임베딩 생성 시작...\n",
      "시작 시점: 🍎 MPS 사용 중 (메모리 정보 제한적)\n",
      "\n",
      "1. 요약문 임베딩 중...\n",
      "시작 전: 🍎 MPS 사용 중 (메모리 정보 제한적)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "요약문:   2%|▏         | 134/8493 [00:29<29:03,  4.79it/s]"
     ]
    }
   ],
   "source": [
    "# ✅ 5. 임베딩 및 유사도 평가\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sentence_transformers import util\n",
    "\n",
    "def get_memory_info():\n",
    "    \"\"\"현재 디바이스에 맞는 메모리 사용량 정보 반환\"\"\"\n",
    "    if device == 'mps':\n",
    "        try:\n",
    "            # MPS는 메모리 정보 조회가 제한적\n",
    "            return \"🍎 MPS 사용 중 (메모리 정보 제한적)\"\n",
    "        except:\n",
    "            return \"🍎 MPS 메모리 정보 조회 불가\"\n",
    "    elif device == 'cuda':\n",
    "        try:\n",
    "            allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "            cached = torch.cuda.memory_reserved() / 1024**3\n",
    "            return f\"🚀 CUDA 메모리 - 할당: {allocated:.2f}GB, 캐시: {cached:.2f}GB\"\n",
    "        except:\n",
    "            return \"🚀 CUDA 메모리 정보 조회 불가\"\n",
    "    else:\n",
    "        return \"💻 CPU 모드\"\n",
    "\n",
    "def encode_with_progress(model, texts, batch_size=32, description=\"Encoding\"):\n",
    "    embeddings = []\n",
    "    print(f\"시작 전: {get_memory_info()}\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=description):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_embeddings = model.encode(batch_texts, convert_to_tensor=True, show_progress_bar=False)\n",
    "        embeddings.append(batch_embeddings)\n",
    "        \n",
    "        # 메모리 정리 (디바이스별 처리)\n",
    "        if i % (batch_size * 10) == 0:\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device == 'mps':\n",
    "                torch.mps.empty_cache()  # MPS 캐시 정리\n",
    "    \n",
    "    result = torch.cat(embeddings, dim=0)\n",
    "    print(f\"완료 후: {get_memory_info()}\")\n",
    "    return result\n",
    "\n",
    "# 시작 전 메모리 상태\n",
    "print(\"🔄 임베딩 생성 시작...\")\n",
    "print(f\"시작 시점: {get_memory_info()}\")\n",
    "\n",
    "# 임베딩 생성\n",
    "print(\"\\n1. 요약문 임베딩 중...\")\n",
    "summary_emb = encode_with_progress(model, summaries, batch_size=32, description=\"요약문\")\n",
    "\n",
    "print(\"\\n2. 원문 임베딩 중...\")\n",
    "original_emb = encode_with_progress(model, originals, batch_size=32, description=\"원문\")\n",
    "\n",
    "# 유사도 계산\n",
    "print(\"\\n3. 유사도 계산 중...\")\n",
    "similarities = util.cos_sim(summary_emb, original_emb).diagonal()\n",
    "score = similarities.mean().item()\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"\\n✅ 평가 결과:\")\n",
    "print(f\"평균 유사도: {score:.4f}\")\n",
    "print(f\"최고 유사도: {similarities.max().item():.4f}\")\n",
    "print(f\"최저 유사도: {similarities.min().item():.4f}\")\n",
    "print(f\"표준편차: {similarities.std().item():.4f}\")\n",
    "\n",
    "# 결과를 데이터에 추가\n",
    "if USE_SAMPLE:\n",
    "    sample_data['KoSBERT_Score'] = similarities.cpu().numpy()\n",
    "    print(f\"\\n상위 5개 기사 점수:\")\n",
    "    print(sample_data[['뉴스 식별자', 'KoSBERT_Score']].head())\n",
    "else:\n",
    "    data['KoSBERT_Score'] = similarities.cpu().numpy()\n",
    "    print(f\"\\n상위 5개 기사 점수:\")\n",
    "    print(data[['뉴스 식별자', 'KoSBERT_Score']].head())\n",
    "\n",
    "print(f\"\\n최종: {get_memory_info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e47ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summaries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m샘플 모드: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summaries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개 데이터로 테스트합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m전체 데이터 모드: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summaries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개 데이터로 평가합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 성능 최적화 설정\u001b[39;00m\n\u001b[1;32m     17\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# GPU 최적화\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summaries' is not defined"
     ]
    }
   ],
   "source": [
    "# ✅ 4. 샘플링 옵션 (빠른 테스트용)\n",
    "USE_SAMPLE = True  # 빠른 테스트를 위해 True로 설정\n",
    "SAMPLE_SIZE = 1000\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    import numpy as np\n",
    "    sample_indices = np.random.choice(len(data), min(SAMPLE_SIZE, len(data)), replace=False)\n",
    "    sample_data = data.iloc[sample_indices].copy()\n",
    "    summaries = sample_data['요약문'].astype(str).tolist()\n",
    "    originals = sample_data['본문'].astype(str).tolist()\n",
    "    print(f\"🚀 샘플 모드: {len(summaries)}개 데이터로 테스트\")\n",
    "else:\n",
    "    print(f\"📊 전체 데이터 모드: {len(summaries)}개 데이터로 평가\")\n",
    "\n",
    "# 현재 설정 확인\n",
    "print(f\"\\n🔧 디바이스 정보:\")\n",
    "print(f\"- 모델 디바이스: {model.device}\")\n",
    "print(f\"- 현재 사용 디바이스: {device}\")\n",
    "\n",
    "# Mac MPS 정보\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"🍎 Mac MPS (Metal Performance Shaders) 지원\")\n",
    "    print(f\"- MPS 사용 가능: {torch.backends.mps.is_built()}\")\n",
    "else:\n",
    "    print(\"❌ MPS 지원 안됨\")\n",
    "\n",
    "# CUDA 정보 (Windows/Linux)\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        device_count = torch.cuda.device_count()\n",
    "        current_device = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(current_device)\n",
    "        \n",
    "        print(f\"🚀 CUDA 정보:\")\n",
    "        print(f\"- GPU 개수: {device_count}\")\n",
    "        print(f\"- 현재 GPU: {device_name}\")\n",
    "        \n",
    "        total_memory = torch.cuda.get_device_properties(current_device).total_memory\n",
    "        allocated = torch.cuda.memory_allocated(current_device)\n",
    "        cached = torch.cuda.memory_reserved(current_device)\n",
    "        \n",
    "        print(f\"- 총 GPU 메모리: {total_memory / 1024**3:.1f}GB\")\n",
    "        print(f\"- 할당된 메모리: {allocated / 1024**3:.2f}GB\")\n",
    "        print(f\"- 캐시된 메모리: {cached / 1024**3:.2f}GB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"- CUDA 정보 조회 중 오류: {e}\")\n",
    "\n",
    "# CPU 정보\n",
    "if device == 'cpu':\n",
    "    print(\"💻 CPU 모드로 실행됩니다\")\n",
    "    \n",
    "print(f\"\\n📊 처리할 데이터 개수: {len(summaries)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
