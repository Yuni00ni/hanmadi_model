{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.13/site-packages (5.0.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers pandas tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36eef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍎 Mac GPU (MPS)를 사용합니다\n",
      "선택된 디바이스: mps\n",
      "✅ 모델을 mps로 이동완료\n",
      "merged_df 크기: (10952, 9)\n",
      "original_df 크기: (10952, 19)\n"
     ]
    }
   ],
   "source": [
    "# ✅ 1. 모델 로드 (한국어 SBERT)\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"🍎 Mac GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"🚀 NVIDIA GPU (CUDA)\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"💻 CPU\")\n",
    "\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "try:\n",
    "    model = model.to(device)\n",
    "    print(f\"✅ 모델을 {device}로 이동완료\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ {device} 오류: {e}\")\n",
    "    device = 'cpu'\n",
    "    model = model.to(device)\n",
    "    print(\"🔄 CPU로 fallback\")\n",
    "\n",
    "# 새로운 데이터 파일 불러오기\n",
    "original_df = pd.read_csv(\"crawling_origin.csv\")\n",
    "summary_df = pd.read_csv(\"news_summaries.csv\")\n",
    "\n",
    "print(f\"원본 전문: {original_df.shape}\")\n",
    "print(f\"KoBERT 요약: {summary_df.shape}\")\n",
    "\n",
    "# 데이터 컬럼 확인\n",
    "print(f\"\\n원본 컬럼: {original_df.columns.tolist()}\")\n",
    "print(f\"요약 컬럼: {summary_df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ffd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "병합된 데이터 크기: (271748, 27)\n",
      "요약문 개수: 271748, 원문 개수: 271748\n",
      "\n",
      "첫 번째 요약문 예시:\n",
      "이재명 대통령은 경기도 가평과 충남 서산·예산, 전남 담양, 경남 산청·합천 등 6개 시군을 특별재난지역으로 선포했는데, 엄혹한 현장에서 음주가무를 즐기는 공직자들의 처신 문제도 거론했다.\n",
      "\n",
      "첫 번째 원문 예시:\n",
      "[앵커]\n",
      "\n",
      " 이재명 대통령이 경기도 가평과 전남 담양, 경남 산청 등 6개 시군을 특별재난지역으로 선포했습니다.\n",
      "\n",
      " 이 대통령은 재난 상황에서 부적절한 공직자들의 처신 문제도 거론했는데, 엄혹한 현장에서 음주가무를 즐기는 정신 나간 경우도 있었다며 엄히 단속하라고 주문했습니다.\n",
      "\n",
      " 보도에 이희연 기자입니다.\n",
      "\n",
      " [리포트]\n",
      "\n",
      "경기도 가평과 충남 서산 예산..\n"
     ]
    }
   ],
   "source": [
    "# 데이터 병합 (공통 식별자 기준)\n",
    "# 컬럼명을 확인한 후 적절한 key로 merge (예: 'id', 'news_id', 'index' 등)\n",
    "\n",
    "# 임시로 인덱스 기준 병합 (실제 컬럼명에 따라 수정 필요)\n",
    "if len(original_df) == len(summary_df):\n",
    "    # 길이가 같으면 인덱스 기준으로 병합\n",
    "    data = pd.concat([original_df.reset_index(drop=True), summary_df.reset_index(drop=True)], axis=1)\n",
    "    print(\"✅ 인덱스 기준 병합 완료\")\n",
    "else:\n",
    "    # 공통 컬럼이 있다면 해당 컬럼으로 merge\n",
    "    # 예시: data = pd.merge(original_df, summary_df, on='news_id', how='inner')\n",
    "    print(\"⚠️ 데이터 길이가 다릅니다. 공통 식별자로 병합이 필요합니다.\")\n",
    "    print(\"컬럼을 확인한 후 적절한 merge key를 설정하세요.\")\n",
    "\n",
    "# 원본 전문과 요약문 컬럼 추출 (실제 컬럼명에 맞게 수정)\n",
    "# 예상 컬럼명들: 'content', 'article', 'text', 'summary', 'kobert_summary' 등\n",
    "try:\n",
    "    # 원본 전문 컬럼 찾기\n",
    "    original_cols = [col for col in original_df.columns if any(keyword in col.lower() \n",
    "                    for keyword in ['content', 'article', 'text', '본문', '전문'])]\n",
    "    \n",
    "    # 요약문 컬럼 찾기  \n",
    "    summary_cols = [col for col in summary_df.columns if any(keyword in col.lower() \n",
    "                   for keyword in ['summary', '요약', 'kobert'])]\n",
    "    \n",
    "    if original_cols and summary_cols:\n",
    "        originals = data[original_cols[0]].astype(str).tolist()\n",
    "        summaries = data[summary_cols[0]].astype(str).tolist()\n",
    "        print(f\"✅ 원본: {original_cols[0]}, 요약: {summary_cols[0]}\")\n",
    "    else:\n",
    "        print(\"❌ 컬럼을 찾을 수 없습니다. 수동으로 설정하세요:\")\n",
    "        print(\"원본 컬럼들:\", original_df.columns.tolist())\n",
    "        print(\"요약 컬럼들:\", summary_df.columns.tolist())\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ 컬럼 처리 오류: {e}\")\n",
    "    print(\"수동으로 컬럼명을 지정하세요:\")\n",
    "    # originals = data['컬럼명'].astype(str).tolist()\n",
    "    # summaries = data['컬럼명'].astype(str).tolist()\n",
    "\n",
    "print(f\"\\n병합된 데이터: {data.shape}\")\n",
    "print(f\"원본: {len(originals)}, 요약: {len(summaries)}\")\n",
    "print(f\"\\n원본 예시: {originals[0][:200]}...\")\n",
    "print(f\"KoBERT 요약 예시: {summaries[0][:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04106ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 임베딩 생성 시작...\n",
      "시작 시점: 🍎 MPS 사용 중 (메모리 정보 제한적)\n",
      "\n",
      "1. 요약문 임베딩 중...\n",
      "시작 전: 🍎 MPS 사용 중 (메모리 정보 제한적)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "요약문:  41%|████      | 3457/8493 [11:46<17:08,  4.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# 임베딩 생성\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m1. 요약문 임베딩 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m summary_emb \u001b[38;5;241m=\u001b[39m encode_with_progress(model, summaries, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m요약문\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. 원문 임베딩 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m original_emb \u001b[38;5;241m=\u001b[39m encode_with_progress(model, originals, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m원문\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m, in \u001b[0;36mencode_with_progress\u001b[0;34m(model, texts, batch_size, description)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size), desc\u001b[38;5;241m=\u001b[39mdescription):\n\u001b[1;32m     29\u001b[0m     batch_texts \u001b[38;5;241m=\u001b[39m texts[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 30\u001b[0m     batch_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(batch_texts, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(batch_embeddings)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# 메모리 정리 (디바이스별 처리)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1048\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m   1040\u001b[0m             features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m   1041\u001b[0m                 (\n\u001b[1;32m   1042\u001b[0m                     features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1046\u001b[0m             )\n\u001b[0;32m-> 1048\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m   1049\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sentence_transformers/util.py:1444\u001b[0m, in \u001b[0;36mbatch_to_device\u001b[0;34m(batch, target_device)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch[key], Tensor):\n\u001b[0;32m-> 1444\u001b[0m         batch[key] \u001b[38;5;241m=\u001b[39m batch[key]\u001b[38;5;241m.\u001b[39mto(target_device)\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_memory_info():\n",
    "    if device == 'mps':\n",
    "        return \"🍎 MPS 사용 중\"\n",
    "    elif device == 'cuda':\n",
    "        try:\n",
    "            allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "            cached = torch.cuda.memory_reserved() / 1024**3\n",
    "            return f\"🚀 CUDA - 할당: {allocated:.2f}GB, 캐시: {cached:.2f}GB\"\n",
    "        except:\n",
    "            return \"🚀 CUDA 메모리 정보 불가\"\n",
    "    else:\n",
    "        return \"💻 CPU 모드\"\n",
    "\n",
    "def encode_with_progress(model, texts, batch_size=32, description=\"Encoding\"):\n",
    "    embeddings = []\n",
    "    print(f\"시작: {get_memory_info()}\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=description):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_embeddings = model.encode(batch_texts, convert_to_tensor=True, show_progress_bar=False)\n",
    "        embeddings.append(batch_embeddings)\n",
    "        \n",
    "        if i % (batch_size * 10) == 0:\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device == 'mps':\n",
    "                torch.mps.empty_cache()\n",
    "    \n",
    "    result = torch.cat(embeddings, dim=0)\n",
    "    print(f\"완료: {get_memory_info()}\")\n",
    "    return result\n",
    "\n",
    "print(\"🔄 KoBERT 요약 성능 평가 시작...\")\n",
    "print(f\"시작점: {get_memory_info()}\")\n",
    "\n",
    "print(\"\\n1. 원본 전문 임베딩...\")\n",
    "original_emb = encode_with_progress(model, originals, batch_size=32, description=\"원본 전문\")\n",
    "\n",
    "print(\"\\n2. KoBERT 요약 임베딩...\")\n",
    "summary_emb = encode_with_progress(model, summaries, batch_size=32, description=\"KoBERT 요약\")\n",
    "\n",
    "print(\"\\n3. 의미 유사도 계산...\")\n",
    "similarities = util.cos_sim(summary_emb, original_emb).diagonal()\n",
    "score = similarities.mean().item()\n",
    "\n",
    "print(f\"\\n✅ KoBERT 요약 성능 평가 결과:\")\n",
    "print(f\"📊 평균 의미 유사도: {score:.4f}\")\n",
    "print(f\"📈 최고 유사도: {similarities.max().item():.4f}\")\n",
    "print(f\"📉 최저 유사도: {similarities.min().item():.4f}\")\n",
    "print(f\"📏 표준편차: {similarities.std().item():.4f}\")\n",
    "\n",
    "# 성능 등급 분류\n",
    "if score >= 0.8:\n",
    "    grade = \"🏆 우수\"\n",
    "elif score >= 0.7:\n",
    "    grade = \"👍 양호\"\n",
    "elif score >= 0.6:\n",
    "    grade = \"⚠️ 보통\"\n",
    "else:\n",
    "    grade = \"❌ 개선필요\"\n",
    "\n",
    "print(f\"🎯 KoBERT 요약 성능: {grade} ({score:.4f})\")\n",
    "\n",
    "# 결과를 데이터에 추가\n",
    "similarity_scores = similarities.cpu().numpy()\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    sample_data['KoBERT_Similarity'] = similarity_scores\n",
    "    print(f\"\\n📋 상위 5개 기사 유사도:\")\n",
    "    print(sample_data[['KoBERT_Similarity']].head())\n",
    "    \n",
    "    # 우수한 요약 예시 (상위 3개)\n",
    "    top_indices = np.argsort(similarity_scores)[-3:]\n",
    "    print(f\"\\n🏆 우수한 요약 예시 (유사도 상위 3개):\")\n",
    "    for i, idx in enumerate(top_indices[::-1]):\n",
    "        print(f\"\\n--- {i+1}위 (유사도: {similarity_scores[idx]:.4f}) ---\")\n",
    "        print(f\"원본: {originals[idx][:150]}...\")\n",
    "        print(f\"요약: {summaries[idx][:100]}...\")\n",
    "\n",
    "print(f\"\\n최종: {get_memory_info()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e47ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summaries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m샘플 모드: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summaries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개 데이터로 테스트합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m전체 데이터 모드: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summaries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개 데이터로 평가합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 성능 최적화 설정\u001b[39;00m\n\u001b[1;32m     17\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# GPU 최적화\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summaries' is not defined"
     ]
    }
   ],
   "source": [
    "# ✅ 4. 샘플링 옵션 (빠른 테스트용)\n",
    "USE_SAMPLE = True  # 빠른 테스트를 위해 True로 설정\n",
    "SAMPLE_SIZE = 1000\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    import numpy as np\n",
    "    sample_indices = np.random.choice(len(data), min(SAMPLE_SIZE, len(data)), replace=False)\n",
    "    sample_data = data.iloc[sample_indices].copy()\n",
    "    summaries = sample_data['요약문'].astype(str).tolist()\n",
    "    originals = sample_data['본문'].astype(str).tolist()\n",
    "    print(f\"🚀 샘플 모드: {len(summaries)}개 데이터로 테스트\")\n",
    "else:\n",
    "    print(f\"📊 전체 데이터 모드: {len(summaries)}개 데이터로 평가\")\n",
    "\n",
    "# 현재 설정 확인\n",
    "print(f\"\\n🔧 디바이스 정보:\")\n",
    "print(f\"- 모델 디바이스: {model.device}\")\n",
    "print(f\"- 현재 사용 디바이스: {device}\")\n",
    "\n",
    "# Mac MPS 정보\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"🍎 Mac MPS (Metal Performance Shaders) 지원\")\n",
    "    print(f\"- MPS 사용 가능: {torch.backends.mps.is_built()}\")\n",
    "else:\n",
    "    print(\"❌ MPS 지원 안됨\")\n",
    "\n",
    "# CUDA 정보 (Windows/Linux)\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        device_count = torch.cuda.device_count()\n",
    "        current_device = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(current_device)\n",
    "        \n",
    "        print(f\"🚀 CUDA 정보:\")\n",
    "        print(f\"- GPU 개수: {device_count}\")\n",
    "        print(f\"- 현재 GPU: {device_name}\")\n",
    "        \n",
    "        total_memory = torch.cuda.get_device_properties(current_device).total_memory\n",
    "        allocated = torch.cuda.memory_allocated(current_device)\n",
    "        cached = torch.cuda.memory_reserved(current_device)\n",
    "        \n",
    "        print(f\"- 총 GPU 메모리: {total_memory / 1024**3:.1f}GB\")\n",
    "        print(f\"- 할당된 메모리: {allocated / 1024**3:.2f}GB\")\n",
    "        print(f\"- 캐시된 메모리: {cached / 1024**3:.2f}GB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"- CUDA 정보 조회 중 오류: {e}\")\n",
    "\n",
    "# CPU 정보\n",
    "if device == 'cpu':\n",
    "    print(\"💻 CPU 모드로 실행됩니다\")\n",
    "    \n",
    "print(f\"\\n📊 처리할 데이터 개수: {len(summaries)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
