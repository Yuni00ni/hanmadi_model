{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.13/site-packages (5.0.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers pandas tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36eef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ Mac GPU (MPS)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
      "ì„ íƒëœ ë””ë°”ì´ìŠ¤: mps\n",
      "âœ… ëª¨ë¸ì„ mpsë¡œ ì´ë™ì™„ë£Œ\n",
      "merged_df í¬ê¸°: (10952, 9)\n",
      "original_df í¬ê¸°: (10952, 19)\n"
     ]
    }
   ],
   "source": [
    "# âœ… 1. ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ SBERT)\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"ğŸ Mac GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"ğŸš€ NVIDIA GPU (CUDA)\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"ğŸ’» CPU\")\n",
    "\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "try:\n",
    "    model = model.to(device)\n",
    "    print(f\"âœ… ëª¨ë¸ì„ {device}ë¡œ ì´ë™ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ {device} ì˜¤ë¥˜: {e}\")\n",
    "    device = 'cpu'\n",
    "    model = model.to(device)\n",
    "    print(\"ğŸ”„ CPUë¡œ fallback\")\n",
    "\n",
    "# ìƒˆë¡œìš´ ë°ì´í„° íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "original_df = pd.read_csv(\"crawling_origin.csv\")\n",
    "summary_df = pd.read_csv(\"news_summaries.csv\")\n",
    "\n",
    "print(f\"ì›ë³¸ ì „ë¬¸: {original_df.shape}\")\n",
    "print(f\"KoBERT ìš”ì•½: {summary_df.shape}\")\n",
    "\n",
    "# ë°ì´í„° ì»¬ëŸ¼ í™•ì¸\n",
    "print(f\"\\nì›ë³¸ ì»¬ëŸ¼: {original_df.columns.tolist()}\")\n",
    "print(f\"ìš”ì•½ ì»¬ëŸ¼: {summary_df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ffd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³‘í•©ëœ ë°ì´í„° í¬ê¸°: (271748, 27)\n",
      "ìš”ì•½ë¬¸ ê°œìˆ˜: 271748, ì›ë¬¸ ê°œìˆ˜: 271748\n",
      "\n",
      "ì²« ë²ˆì§¸ ìš”ì•½ë¬¸ ì˜ˆì‹œ:\n",
      "ì´ì¬ëª… ëŒ€í†µë ¹ì€ ê²½ê¸°ë„ ê°€í‰ê³¼ ì¶©ë‚¨ ì„œì‚°Â·ì˜ˆì‚°, ì „ë‚¨ ë‹´ì–‘, ê²½ë‚¨ ì‚°ì²­Â·í•©ì²œ ë“± 6ê°œ ì‹œêµ°ì„ íŠ¹ë³„ì¬ë‚œì§€ì—­ìœ¼ë¡œ ì„ í¬í–ˆëŠ”ë°, ì—„í˜¹í•œ í˜„ì¥ì—ì„œ ìŒì£¼ê°€ë¬´ë¥¼ ì¦ê¸°ëŠ” ê³µì§ìë“¤ì˜ ì²˜ì‹  ë¬¸ì œë„ ê±°ë¡ í–ˆë‹¤.\n",
      "\n",
      "ì²« ë²ˆì§¸ ì›ë¬¸ ì˜ˆì‹œ:\n",
      "[ì•µì»¤]\n",
      "\n",
      " ì´ì¬ëª… ëŒ€í†µë ¹ì´ ê²½ê¸°ë„ ê°€í‰ê³¼ ì „ë‚¨ ë‹´ì–‘, ê²½ë‚¨ ì‚°ì²­ ë“± 6ê°œ ì‹œêµ°ì„ íŠ¹ë³„ì¬ë‚œì§€ì—­ìœ¼ë¡œ ì„ í¬í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      " ì´ ëŒ€í†µë ¹ì€ ì¬ë‚œ ìƒí™©ì—ì„œ ë¶€ì ì ˆí•œ ê³µì§ìë“¤ì˜ ì²˜ì‹  ë¬¸ì œë„ ê±°ë¡ í–ˆëŠ”ë°, ì—„í˜¹í•œ í˜„ì¥ì—ì„œ ìŒì£¼ê°€ë¬´ë¥¼ ì¦ê¸°ëŠ” ì •ì‹  ë‚˜ê°„ ê²½ìš°ë„ ìˆì—ˆë‹¤ë©° ì—„íˆ ë‹¨ì†í•˜ë¼ê³  ì£¼ë¬¸í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      " ë³´ë„ì— ì´í¬ì—° ê¸°ìì…ë‹ˆë‹¤.\n",
      "\n",
      " [ë¦¬í¬íŠ¸]\n",
      "\n",
      "ê²½ê¸°ë„ ê°€í‰ê³¼ ì¶©ë‚¨ ì„œì‚° ì˜ˆì‚°..\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë³‘í•© (ê³µí†µ ì‹ë³„ì ê¸°ì¤€)\n",
    "# ì»¬ëŸ¼ëª…ì„ í™•ì¸í•œ í›„ ì ì ˆí•œ keyë¡œ merge (ì˜ˆ: 'id', 'news_id', 'index' ë“±)\n",
    "\n",
    "# ì„ì‹œë¡œ ì¸ë±ìŠ¤ ê¸°ì¤€ ë³‘í•© (ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë”°ë¼ ìˆ˜ì • í•„ìš”)\n",
    "if len(original_df) == len(summary_df):\n",
    "    # ê¸¸ì´ê°€ ê°™ìœ¼ë©´ ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©\n",
    "    data = pd.concat([original_df.reset_index(drop=True), summary_df.reset_index(drop=True)], axis=1)\n",
    "    print(\"âœ… ì¸ë±ìŠ¤ ê¸°ì¤€ ë³‘í•© ì™„ë£Œ\")\n",
    "else:\n",
    "    # ê³µí†µ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ í•´ë‹¹ ì»¬ëŸ¼ìœ¼ë¡œ merge\n",
    "    # ì˜ˆì‹œ: data = pd.merge(original_df, summary_df, on='news_id', how='inner')\n",
    "    print(\"âš ï¸ ë°ì´í„° ê¸¸ì´ê°€ ë‹¤ë¦…ë‹ˆë‹¤. ê³µí†µ ì‹ë³„ìë¡œ ë³‘í•©ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "    print(\"ì»¬ëŸ¼ì„ í™•ì¸í•œ í›„ ì ì ˆí•œ merge keyë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ì›ë³¸ ì „ë¬¸ê³¼ ìš”ì•½ë¬¸ ì»¬ëŸ¼ ì¶”ì¶œ (ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ê²Œ ìˆ˜ì •)\n",
    "# ì˜ˆìƒ ì»¬ëŸ¼ëª…ë“¤: 'content', 'article', 'text', 'summary', 'kobert_summary' ë“±\n",
    "try:\n",
    "    # ì›ë³¸ ì „ë¬¸ ì»¬ëŸ¼ ì°¾ê¸°\n",
    "    original_cols = [col for col in original_df.columns if any(keyword in col.lower() \n",
    "                    for keyword in ['content', 'article', 'text', 'ë³¸ë¬¸', 'ì „ë¬¸'])]\n",
    "    \n",
    "    # ìš”ì•½ë¬¸ ì»¬ëŸ¼ ì°¾ê¸°  \n",
    "    summary_cols = [col for col in summary_df.columns if any(keyword in col.lower() \n",
    "                   for keyword in ['summary', 'ìš”ì•½', 'kobert'])]\n",
    "    \n",
    "    if original_cols and summary_cols:\n",
    "        originals = data[original_cols[0]].astype(str).tolist()\n",
    "        summaries = data[summary_cols[0]].astype(str).tolist()\n",
    "        print(f\"âœ… ì›ë³¸: {original_cols[0]}, ìš”ì•½: {summary_cols[0]}\")\n",
    "    else:\n",
    "        print(\"âŒ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”:\")\n",
    "        print(\"ì›ë³¸ ì»¬ëŸ¼ë“¤:\", original_df.columns.tolist())\n",
    "        print(\"ìš”ì•½ ì»¬ëŸ¼ë“¤:\", summary_df.columns.tolist())\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì»¬ëŸ¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "    print(\"ìˆ˜ë™ìœ¼ë¡œ ì»¬ëŸ¼ëª…ì„ ì§€ì •í•˜ì„¸ìš”:\")\n",
    "    # originals = data['ì»¬ëŸ¼ëª…'].astype(str).tolist()\n",
    "    # summaries = data['ì»¬ëŸ¼ëª…'].astype(str).tolist()\n",
    "\n",
    "print(f\"\\në³‘í•©ëœ ë°ì´í„°: {data.shape}\")\n",
    "print(f\"ì›ë³¸: {len(originals)}, ìš”ì•½: {len(summaries)}\")\n",
    "print(f\"\\nì›ë³¸ ì˜ˆì‹œ: {originals[0][:200]}...\")\n",
    "print(f\"KoBERT ìš”ì•½ ì˜ˆì‹œ: {summaries[0][:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04106ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ì„ë² ë”© ìƒì„± ì‹œì‘...\n",
      "ì‹œì‘ ì‹œì : ğŸ MPS ì‚¬ìš© ì¤‘ (ë©”ëª¨ë¦¬ ì •ë³´ ì œí•œì )\n",
      "\n",
      "1. ìš”ì•½ë¬¸ ì„ë² ë”© ì¤‘...\n",
      "ì‹œì‘ ì „: ğŸ MPS ì‚¬ìš© ì¤‘ (ë©”ëª¨ë¦¬ ì •ë³´ ì œí•œì )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ìš”ì•½ë¬¸:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 3457/8493 [11:46<17:08,  4.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# ì„ë² ë”© ìƒì„±\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m1. ìš”ì•½ë¬¸ ì„ë² ë”© ì¤‘...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m summary_emb \u001b[38;5;241m=\u001b[39m encode_with_progress(model, summaries, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mìš”ì•½ë¬¸\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. ì›ë¬¸ ì„ë² ë”© ì¤‘...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m original_emb \u001b[38;5;241m=\u001b[39m encode_with_progress(model, originals, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì›ë¬¸\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 30\u001b[0m, in \u001b[0;36mencode_with_progress\u001b[0;34m(model, texts, batch_size, description)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size), desc\u001b[38;5;241m=\u001b[39mdescription):\n\u001b[1;32m     29\u001b[0m     batch_texts \u001b[38;5;241m=\u001b[39m texts[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 30\u001b[0m     batch_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(batch_texts, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     31\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(batch_embeddings)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# ë©”ëª¨ë¦¬ ì •ë¦¬ (ë””ë°”ì´ìŠ¤ë³„ ì²˜ë¦¬)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:1048\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m   1040\u001b[0m             features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m   1041\u001b[0m                 (\n\u001b[1;32m   1042\u001b[0m                     features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1046\u001b[0m             )\n\u001b[0;32m-> 1048\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m   1049\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sentence_transformers/util.py:1444\u001b[0m, in \u001b[0;36mbatch_to_device\u001b[0;34m(batch, target_device)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch[key], Tensor):\n\u001b[0;32m-> 1444\u001b[0m         batch[key] \u001b[38;5;241m=\u001b[39m batch[key]\u001b[38;5;241m.\u001b[39mto(target_device)\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_memory_info():\n",
    "    if device == 'mps':\n",
    "        return \"ğŸ MPS ì‚¬ìš© ì¤‘\"\n",
    "    elif device == 'cuda':\n",
    "        try:\n",
    "            allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "            cached = torch.cuda.memory_reserved() / 1024**3\n",
    "            return f\"ğŸš€ CUDA - í• ë‹¹: {allocated:.2f}GB, ìºì‹œ: {cached:.2f}GB\"\n",
    "        except:\n",
    "            return \"ğŸš€ CUDA ë©”ëª¨ë¦¬ ì •ë³´ ë¶ˆê°€\"\n",
    "    else:\n",
    "        return \"ğŸ’» CPU ëª¨ë“œ\"\n",
    "\n",
    "def encode_with_progress(model, texts, batch_size=32, description=\"Encoding\"):\n",
    "    embeddings = []\n",
    "    print(f\"ì‹œì‘: {get_memory_info()}\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=description):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_embeddings = model.encode(batch_texts, convert_to_tensor=True, show_progress_bar=False)\n",
    "        embeddings.append(batch_embeddings)\n",
    "        \n",
    "        if i % (batch_size * 10) == 0:\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device == 'mps':\n",
    "                torch.mps.empty_cache()\n",
    "    \n",
    "    result = torch.cat(embeddings, dim=0)\n",
    "    print(f\"ì™„ë£Œ: {get_memory_info()}\")\n",
    "    return result\n",
    "\n",
    "print(\"ğŸ”„ KoBERT ìš”ì•½ ì„±ëŠ¥ í‰ê°€ ì‹œì‘...\")\n",
    "print(f\"ì‹œì‘ì : {get_memory_info()}\")\n",
    "\n",
    "print(\"\\n1. ì›ë³¸ ì „ë¬¸ ì„ë² ë”©...\")\n",
    "original_emb = encode_with_progress(model, originals, batch_size=32, description=\"ì›ë³¸ ì „ë¬¸\")\n",
    "\n",
    "print(\"\\n2. KoBERT ìš”ì•½ ì„ë² ë”©...\")\n",
    "summary_emb = encode_with_progress(model, summaries, batch_size=32, description=\"KoBERT ìš”ì•½\")\n",
    "\n",
    "print(\"\\n3. ì˜ë¯¸ ìœ ì‚¬ë„ ê³„ì‚°...\")\n",
    "similarities = util.cos_sim(summary_emb, original_emb).diagonal()\n",
    "score = similarities.mean().item()\n",
    "\n",
    "print(f\"\\nâœ… KoBERT ìš”ì•½ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼:\")\n",
    "print(f\"ğŸ“Š í‰ê·  ì˜ë¯¸ ìœ ì‚¬ë„: {score:.4f}\")\n",
    "print(f\"ğŸ“ˆ ìµœê³  ìœ ì‚¬ë„: {similarities.max().item():.4f}\")\n",
    "print(f\"ğŸ“‰ ìµœì € ìœ ì‚¬ë„: {similarities.min().item():.4f}\")\n",
    "print(f\"ğŸ“ í‘œì¤€í¸ì°¨: {similarities.std().item():.4f}\")\n",
    "\n",
    "# ì„±ëŠ¥ ë“±ê¸‰ ë¶„ë¥˜\n",
    "if score >= 0.8:\n",
    "    grade = \"ğŸ† ìš°ìˆ˜\"\n",
    "elif score >= 0.7:\n",
    "    grade = \"ğŸ‘ ì–‘í˜¸\"\n",
    "elif score >= 0.6:\n",
    "    grade = \"âš ï¸ ë³´í†µ\"\n",
    "else:\n",
    "    grade = \"âŒ ê°œì„ í•„ìš”\"\n",
    "\n",
    "print(f\"ğŸ¯ KoBERT ìš”ì•½ ì„±ëŠ¥: {grade} ({score:.4f})\")\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ë°ì´í„°ì— ì¶”ê°€\n",
    "similarity_scores = similarities.cpu().numpy()\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    sample_data['KoBERT_Similarity'] = similarity_scores\n",
    "    print(f\"\\nğŸ“‹ ìƒìœ„ 5ê°œ ê¸°ì‚¬ ìœ ì‚¬ë„:\")\n",
    "    print(sample_data[['KoBERT_Similarity']].head())\n",
    "    \n",
    "    # ìš°ìˆ˜í•œ ìš”ì•½ ì˜ˆì‹œ (ìƒìœ„ 3ê°œ)\n",
    "    top_indices = np.argsort(similarity_scores)[-3:]\n",
    "    print(f\"\\nğŸ† ìš°ìˆ˜í•œ ìš”ì•½ ì˜ˆì‹œ (ìœ ì‚¬ë„ ìƒìœ„ 3ê°œ):\")\n",
    "    for i, idx in enumerate(top_indices[::-1]):\n",
    "        print(f\"\\n--- {i+1}ìœ„ (ìœ ì‚¬ë„: {similarity_scores[idx]:.4f}) ---\")\n",
    "        print(f\"ì›ë³¸: {originals[idx][:150]}...\")\n",
    "        print(f\"ìš”ì•½: {summaries[idx][:100]}...\")\n",
    "\n",
    "print(f\"\\nìµœì¢…: {get_memory_info()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e47ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summaries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mìƒ˜í”Œ ëª¨ë“œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summaries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mê°œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì „ì²´ ë°ì´í„° ëª¨ë“œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summaries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mê°œ ë°ì´í„°ë¡œ í‰ê°€í•©ë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ì„±ëŠ¥ ìµœì í™” ì„¤ì •\u001b[39;00m\n\u001b[1;32m     17\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# GPU ìµœì í™”\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summaries' is not defined"
     ]
    }
   ],
   "source": [
    "# âœ… 4. ìƒ˜í”Œë§ ì˜µì…˜ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)\n",
    "USE_SAMPLE = True  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ Trueë¡œ ì„¤ì •\n",
    "SAMPLE_SIZE = 1000\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    import numpy as np\n",
    "    sample_indices = np.random.choice(len(data), min(SAMPLE_SIZE, len(data)), replace=False)\n",
    "    sample_data = data.iloc[sample_indices].copy()\n",
    "    summaries = sample_data['ìš”ì•½ë¬¸'].astype(str).tolist()\n",
    "    originals = sample_data['ë³¸ë¬¸'].astype(str).tolist()\n",
    "    print(f\"ğŸš€ ìƒ˜í”Œ ëª¨ë“œ: {len(summaries)}ê°œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\")\n",
    "else:\n",
    "    print(f\"ğŸ“Š ì „ì²´ ë°ì´í„° ëª¨ë“œ: {len(summaries)}ê°œ ë°ì´í„°ë¡œ í‰ê°€\")\n",
    "\n",
    "# í˜„ì¬ ì„¤ì • í™•ì¸\n",
    "print(f\"\\nğŸ”§ ë””ë°”ì´ìŠ¤ ì •ë³´:\")\n",
    "print(f\"- ëª¨ë¸ ë””ë°”ì´ìŠ¤: {model.device}\")\n",
    "print(f\"- í˜„ì¬ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# Mac MPS ì •ë³´\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"ğŸ Mac MPS (Metal Performance Shaders) ì§€ì›\")\n",
    "    print(f\"- MPS ì‚¬ìš© ê°€ëŠ¥: {torch.backends.mps.is_built()}\")\n",
    "else:\n",
    "    print(\"âŒ MPS ì§€ì› ì•ˆë¨\")\n",
    "\n",
    "# CUDA ì •ë³´ (Windows/Linux)\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        device_count = torch.cuda.device_count()\n",
    "        current_device = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(current_device)\n",
    "        \n",
    "        print(f\"ğŸš€ CUDA ì •ë³´:\")\n",
    "        print(f\"- GPU ê°œìˆ˜: {device_count}\")\n",
    "        print(f\"- í˜„ì¬ GPU: {device_name}\")\n",
    "        \n",
    "        total_memory = torch.cuda.get_device_properties(current_device).total_memory\n",
    "        allocated = torch.cuda.memory_allocated(current_device)\n",
    "        cached = torch.cuda.memory_reserved(current_device)\n",
    "        \n",
    "        print(f\"- ì´ GPU ë©”ëª¨ë¦¬: {total_memory / 1024**3:.1f}GB\")\n",
    "        print(f\"- í• ë‹¹ëœ ë©”ëª¨ë¦¬: {allocated / 1024**3:.2f}GB\")\n",
    "        print(f\"- ìºì‹œëœ ë©”ëª¨ë¦¬: {cached / 1024**3:.2f}GB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"- CUDA ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# CPU ì •ë³´\n",
    "if device == 'cpu':\n",
    "    print(\"ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤\")\n",
    "    \n",
    "print(f\"\\nğŸ“Š ì²˜ë¦¬í•  ë°ì´í„° ê°œìˆ˜: {len(summaries)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
