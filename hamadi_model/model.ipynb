{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f9836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.13/site-packages (5.0.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# âœ… KoSentenceBERT ê¸°ë°˜ ì˜ë¯¸ ìœ ì‚¬ë„ í‰ê°€ ì½”ë“œ\n",
    "# ì„¤ì¹˜ (ìµœì´ˆ 1íšŒë§Œ í•„ìš”)\n",
    "%pip install sentence-transformers pandas\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36eef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ Mac GPU (MPS)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
      "ì„ íƒëœ ë””ë°”ì´ìŠ¤: mps\n",
      "âœ… ëª¨ë¸ì„ mpsë¡œ ì´ë™ì™„ë£Œ\n",
      "merged_df í¬ê¸°: (10952, 9)\n",
      "original_df í¬ê¸°: (10952, 19)\n"
     ]
    }
   ],
   "source": [
    "# âœ… 1. ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ SBERT)\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Mac GPU (MPS) ì‚¬ìš© ì„¤ì •\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"ğŸ Mac GPU (MPS)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"ğŸš€ NVIDIA GPU (CUDA)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"ğŸ’» CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\")\n",
    "\n",
    "print(f\"ì„ íƒëœ ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ ë° ë””ë°”ì´ìŠ¤ ì´ë™\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "try:\n",
    "    model = model.to(device)\n",
    "    print(f\"âœ… ëª¨ë¸ì„ {device}ë¡œ ì´ë™ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ {device} ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    device = 'cpu'\n",
    "    model = model.to(device)\n",
    "    print(\"ğŸ”„ CPUë¡œ fallback\")\n",
    "\n",
    "# âœ… 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "merged_df = pd.read_csv(\"merged_news_data (3).csv\")\n",
    "original_df = pd.read_csv(\"NewsResult_2025ë‰´ìŠ¤.xlsx - sheet.csv\")\n",
    "\n",
    "print(f\"merged_df í¬ê¸°: {merged_df.shape}\")\n",
    "print(f\"original_df í¬ê¸°: {original_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17ffd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³‘í•©ëœ ë°ì´í„° í¬ê¸°: (271748, 27)\n",
      "ìš”ì•½ë¬¸ ê°œìˆ˜: 271748, ì›ë¬¸ ê°œìˆ˜: 271748\n",
      "\n",
      "ì²« ë²ˆì§¸ ìš”ì•½ë¬¸ ì˜ˆì‹œ:\n",
      "ì´ì¬ëª… ëŒ€í†µë ¹ì€ ê²½ê¸°ë„ ê°€í‰ê³¼ ì¶©ë‚¨ ì„œì‚°Â·ì˜ˆì‚°, ì „ë‚¨ ë‹´ì–‘, ê²½ë‚¨ ì‚°ì²­Â·í•©ì²œ ë“± 6ê°œ ì‹œêµ°ì„ íŠ¹ë³„ì¬ë‚œì§€ì—­ìœ¼ë¡œ ì„ í¬í–ˆëŠ”ë°, ì—„í˜¹í•œ í˜„ì¥ì—ì„œ ìŒì£¼ê°€ë¬´ë¥¼ ì¦ê¸°ëŠ” ê³µì§ìë“¤ì˜ ì²˜ì‹  ë¬¸ì œë„ ê±°ë¡ í–ˆë‹¤.\n",
      "\n",
      "ì²« ë²ˆì§¸ ì›ë¬¸ ì˜ˆì‹œ:\n",
      "[ì•µì»¤]\n",
      "\n",
      " ì´ì¬ëª… ëŒ€í†µë ¹ì´ ê²½ê¸°ë„ ê°€í‰ê³¼ ì „ë‚¨ ë‹´ì–‘, ê²½ë‚¨ ì‚°ì²­ ë“± 6ê°œ ì‹œêµ°ì„ íŠ¹ë³„ì¬ë‚œì§€ì—­ìœ¼ë¡œ ì„ í¬í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      " ì´ ëŒ€í†µë ¹ì€ ì¬ë‚œ ìƒí™©ì—ì„œ ë¶€ì ì ˆí•œ ê³µì§ìë“¤ì˜ ì²˜ì‹  ë¬¸ì œë„ ê±°ë¡ í–ˆëŠ”ë°, ì—„í˜¹í•œ í˜„ì¥ì—ì„œ ìŒì£¼ê°€ë¬´ë¥¼ ì¦ê¸°ëŠ” ì •ì‹  ë‚˜ê°„ ê²½ìš°ë„ ìˆì—ˆë‹¤ë©° ì—„íˆ ë‹¨ì†í•˜ë¼ê³  ì£¼ë¬¸í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      " ë³´ë„ì— ì´í¬ì—° ê¸°ìì…ë‹ˆë‹¤.\n",
      "\n",
      " [ë¦¬í¬íŠ¸]\n",
      "\n",
      "ê²½ê¸°ë„ ê°€í‰ê³¼ ì¶©ë‚¨ ì„œì‚° ì˜ˆì‚°..\n"
     ]
    }
   ],
   "source": [
    "# âœ… 3. ë°ì´í„° ë³‘í•© ë° ì¤€ë¹„\n",
    "data = pd.merge(merged_df, original_df, on='ë‰´ìŠ¤ ì‹ë³„ì')\n",
    "summaries = data['ìš”ì•½ë¬¸'].astype(str).tolist()\n",
    "originals = data['ë³¸ë¬¸'].astype(str).tolist()\n",
    "\n",
    "print(f\"ë³‘í•©ëœ ë°ì´í„° í¬ê¸°: {data.shape}\")\n",
    "print(f\"ìš”ì•½ë¬¸ ê°œìˆ˜: {len(summaries)}, ì›ë¬¸ ê°œìˆ˜: {len(originals)}\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ìš”ì•½ë¬¸ê³¼ ì›ë¬¸ ì˜ˆì‹œ í™•ì¸\n",
    "print(\"\\nì²« ë²ˆì§¸ ìš”ì•½ë¬¸ ì˜ˆì‹œ:\")\n",
    "print(summaries[0][:200] + \"...\" if len(summaries[0]) > 200 else summaries[0])\n",
    "print(\"\\nì²« ë²ˆì§¸ ì›ë¬¸ ì˜ˆì‹œ:\")\n",
    "print(originals[0][:200] + \"...\" if len(originals[0]) > 200 else originals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04106ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ì„ë² ë”© ìƒì„± ì‹œì‘...\n",
      "ì‹œì‘ ì‹œì : ğŸ MPS ì‚¬ìš© ì¤‘ (ë©”ëª¨ë¦¬ ì •ë³´ ì œí•œì )\n",
      "\n",
      "1. ìš”ì•½ë¬¸ ì„ë² ë”© ì¤‘...\n",
      "ì‹œì‘ ì „: ğŸ MPS ì‚¬ìš© ì¤‘ (ë©”ëª¨ë¦¬ ì •ë³´ ì œí•œì )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ìš”ì•½ë¬¸:   2%|â–         | 134/8493 [00:29<29:03,  4.79it/s]"
     ]
    }
   ],
   "source": [
    "# âœ… 5. ì„ë² ë”© ë° ìœ ì‚¬ë„ í‰ê°€\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sentence_transformers import util\n",
    "\n",
    "def get_memory_info():\n",
    "    \"\"\"í˜„ì¬ ë””ë°”ì´ìŠ¤ì— ë§ëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´ ë°˜í™˜\"\"\"\n",
    "    if device == 'mps':\n",
    "        try:\n",
    "            # MPSëŠ” ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒê°€ ì œí•œì \n",
    "            return \"ğŸ MPS ì‚¬ìš© ì¤‘ (ë©”ëª¨ë¦¬ ì •ë³´ ì œí•œì )\"\n",
    "        except:\n",
    "            return \"ğŸ MPS ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ ë¶ˆê°€\"\n",
    "    elif device == 'cuda':\n",
    "        try:\n",
    "            allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "            cached = torch.cuda.memory_reserved() / 1024**3\n",
    "            return f\"ğŸš€ CUDA ë©”ëª¨ë¦¬ - í• ë‹¹: {allocated:.2f}GB, ìºì‹œ: {cached:.2f}GB\"\n",
    "        except:\n",
    "            return \"ğŸš€ CUDA ë©”ëª¨ë¦¬ ì •ë³´ ì¡°íšŒ ë¶ˆê°€\"\n",
    "    else:\n",
    "        return \"ğŸ’» CPU ëª¨ë“œ\"\n",
    "\n",
    "def encode_with_progress(model, texts, batch_size=32, description=\"Encoding\"):\n",
    "    embeddings = []\n",
    "    print(f\"ì‹œì‘ ì „: {get_memory_info()}\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=description):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_embeddings = model.encode(batch_texts, convert_to_tensor=True, show_progress_bar=False)\n",
    "        embeddings.append(batch_embeddings)\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ë””ë°”ì´ìŠ¤ë³„ ì²˜ë¦¬)\n",
    "        if i % (batch_size * 10) == 0:\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "            elif device == 'mps':\n",
    "                torch.mps.empty_cache()  # MPS ìºì‹œ ì •ë¦¬\n",
    "    \n",
    "    result = torch.cat(embeddings, dim=0)\n",
    "    print(f\"ì™„ë£Œ í›„: {get_memory_info()}\")\n",
    "    return result\n",
    "\n",
    "# ì‹œì‘ ì „ ë©”ëª¨ë¦¬ ìƒíƒœ\n",
    "print(\"ğŸ”„ ì„ë² ë”© ìƒì„± ì‹œì‘...\")\n",
    "print(f\"ì‹œì‘ ì‹œì : {get_memory_info()}\")\n",
    "\n",
    "# ì„ë² ë”© ìƒì„±\n",
    "print(\"\\n1. ìš”ì•½ë¬¸ ì„ë² ë”© ì¤‘...\")\n",
    "summary_emb = encode_with_progress(model, summaries, batch_size=32, description=\"ìš”ì•½ë¬¸\")\n",
    "\n",
    "print(\"\\n2. ì›ë¬¸ ì„ë² ë”© ì¤‘...\")\n",
    "original_emb = encode_with_progress(model, originals, batch_size=32, description=\"ì›ë¬¸\")\n",
    "\n",
    "# ìœ ì‚¬ë„ ê³„ì‚°\n",
    "print(\"\\n3. ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...\")\n",
    "similarities = util.cos_sim(summary_emb, original_emb).diagonal()\n",
    "score = similarities.mean().item()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"\\nâœ… í‰ê°€ ê²°ê³¼:\")\n",
    "print(f\"í‰ê·  ìœ ì‚¬ë„: {score:.4f}\")\n",
    "print(f\"ìµœê³  ìœ ì‚¬ë„: {similarities.max().item():.4f}\")\n",
    "print(f\"ìµœì € ìœ ì‚¬ë„: {similarities.min().item():.4f}\")\n",
    "print(f\"í‘œì¤€í¸ì°¨: {similarities.std().item():.4f}\")\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ë°ì´í„°ì— ì¶”ê°€\n",
    "if USE_SAMPLE:\n",
    "    sample_data['KoSBERT_Score'] = similarities.cpu().numpy()\n",
    "    print(f\"\\nìƒìœ„ 5ê°œ ê¸°ì‚¬ ì ìˆ˜:\")\n",
    "    print(sample_data[['ë‰´ìŠ¤ ì‹ë³„ì', 'KoSBERT_Score']].head())\n",
    "else:\n",
    "    data['KoSBERT_Score'] = similarities.cpu().numpy()\n",
    "    print(f\"\\nìƒìœ„ 5ê°œ ê¸°ì‚¬ ì ìˆ˜:\")\n",
    "    print(data[['ë‰´ìŠ¤ ì‹ë³„ì', 'KoSBERT_Score']].head())\n",
    "\n",
    "print(f\"\\nìµœì¢…: {get_memory_info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e47ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summaries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mìƒ˜í”Œ ëª¨ë“œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summaries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mê°œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì „ì²´ ë°ì´í„° ëª¨ë“œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summaries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mê°œ ë°ì´í„°ë¡œ í‰ê°€í•©ë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ì„±ëŠ¥ ìµœì í™” ì„¤ì •\u001b[39;00m\n\u001b[1;32m     17\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# GPU ìµœì í™”\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summaries' is not defined"
     ]
    }
   ],
   "source": [
    "# âœ… 4. ìƒ˜í”Œë§ ì˜µì…˜ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)\n",
    "USE_SAMPLE = True  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ Trueë¡œ ì„¤ì •\n",
    "SAMPLE_SIZE = 1000\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    import numpy as np\n",
    "    sample_indices = np.random.choice(len(data), min(SAMPLE_SIZE, len(data)), replace=False)\n",
    "    sample_data = data.iloc[sample_indices].copy()\n",
    "    summaries = sample_data['ìš”ì•½ë¬¸'].astype(str).tolist()\n",
    "    originals = sample_data['ë³¸ë¬¸'].astype(str).tolist()\n",
    "    print(f\"ğŸš€ ìƒ˜í”Œ ëª¨ë“œ: {len(summaries)}ê°œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\")\n",
    "else:\n",
    "    print(f\"ğŸ“Š ì „ì²´ ë°ì´í„° ëª¨ë“œ: {len(summaries)}ê°œ ë°ì´í„°ë¡œ í‰ê°€\")\n",
    "\n",
    "# í˜„ì¬ ì„¤ì • í™•ì¸\n",
    "print(f\"\\nğŸ”§ ë””ë°”ì´ìŠ¤ ì •ë³´:\")\n",
    "print(f\"- ëª¨ë¸ ë””ë°”ì´ìŠ¤: {model.device}\")\n",
    "print(f\"- í˜„ì¬ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# Mac MPS ì •ë³´\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"ğŸ Mac MPS (Metal Performance Shaders) ì§€ì›\")\n",
    "    print(f\"- MPS ì‚¬ìš© ê°€ëŠ¥: {torch.backends.mps.is_built()}\")\n",
    "else:\n",
    "    print(\"âŒ MPS ì§€ì› ì•ˆë¨\")\n",
    "\n",
    "# CUDA ì •ë³´ (Windows/Linux)\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        device_count = torch.cuda.device_count()\n",
    "        current_device = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(current_device)\n",
    "        \n",
    "        print(f\"ğŸš€ CUDA ì •ë³´:\")\n",
    "        print(f\"- GPU ê°œìˆ˜: {device_count}\")\n",
    "        print(f\"- í˜„ì¬ GPU: {device_name}\")\n",
    "        \n",
    "        total_memory = torch.cuda.get_device_properties(current_device).total_memory\n",
    "        allocated = torch.cuda.memory_allocated(current_device)\n",
    "        cached = torch.cuda.memory_reserved(current_device)\n",
    "        \n",
    "        print(f\"- ì´ GPU ë©”ëª¨ë¦¬: {total_memory / 1024**3:.1f}GB\")\n",
    "        print(f\"- í• ë‹¹ëœ ë©”ëª¨ë¦¬: {allocated / 1024**3:.2f}GB\")\n",
    "        print(f\"- ìºì‹œëœ ë©”ëª¨ë¦¬: {cached / 1024**3:.2f}GB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"- CUDA ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# CPU ì •ë³´\n",
    "if device == 'cpu':\n",
    "    print(\"ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤\")\n",
    "    \n",
    "print(f\"\\nğŸ“Š ì²˜ë¦¬í•  ë°ì´í„° ê°œìˆ˜: {len(summaries)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
